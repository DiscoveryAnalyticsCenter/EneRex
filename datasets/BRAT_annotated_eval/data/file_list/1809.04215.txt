Dynamic Interaction Probabilistic Movement Primitives

Abstract
Human-robot collaboration is on the rise. Robots need to increasingly improve the efficiency and smoothness with which they assist humans by properly anticipating a human's intention. To do so, prediction models need to increase their accuracy and responsiveness. This work builds on top of Interaction Movement Primitives with phase estimation and re-formulates the framework to use dynamic human-motion observations which constantly update anticipatory motions. The original framework only considers a single fixed-duration static human observation which is used to perform only one anticipatory motion. Dynamic observations, with built-in phase estimation, yield a series of updated robot motion distributions. Co-activation is performed between the existing and newest most probably robot motion distribution. This results in smooth anticipatory robot motions that are highly accurate and with enhanced responsiveness.

I. INTRODUCTION
In human-robot interaction (HRI) and human-robot collaboration (HRC) anticipation is key for smoother collaboration. Anticipatory motions are a result of predictions a robot makes as it observes its human counter-part. However, a main drawback in predicting is the trade-off between achieved trajectory and goal-pose accuracy and longer observation periods. The sooner a human trajectory is predicted, the sooner a robot can offer assistance. However, quick predictions may lead to inaccurate robot motions; whilst longer observations may achieve higher accuracy but with lags in responsiveness. Most of the work in HRI anticipation uses fixed-time human observation windows. In this work, we introduce dynamic human observation window as a general-case scenarios for agent observations (static windows, on the other hand, are just a special case). In particular, we are interested to resolve situations when a multiple human motions begin with a similar motion but divert later on. This is typical in situations where the human moves initially to grasp or deliver an object, but is waiting to better understand environmental conditions before transitioning to a final motion. This may occur when external factors like others humans are also working in the current environment (see  #b0 ) for example. In HRI and HRC, numerous approaches have been used to generate robot motion in response to human motion observations. The research is characterized by estimating the human state to generate an appropriate and corresponding robot motion. Some predictive works have focused on optimizing safety and avoiding predicted human-occupancy spaces to avoid collisions  #b0 -  #b2 . Other works like Interaction Probabilistic Motion Primitives (IProMPs)  #b3 -  #b5  generate predictive robot motions based on one-time fixed observations of human motions to achieve physical interactions like: handover tasks. Interactive meshes (IMs)  #b7  learn an interaction model Example of two human motion trajectories that start with a similar path but diverge in the latter half. Static fixed-duration observation techniques do not identify changes that occur in the post-observation period.from human-to-human demonstrations that can be used to continuously update a robot's motion during collaborative tasks. IMs model complex interactions; however they lack (timely) responsiveness. In  #b8 , Parascho's et al. introduced the Probabilistic Movement Primitives (ProMPs) framework to compose complex robot skills from basic movements in a modular control architecture. The framework provided a single unified formulation that enabled probabilistic operations to support the parallel and smooth co-activation of MPs. Tasks could then be generated as sequences of simple or simultaneously activated skills. The ProMP formulation, like Dynamic Motion Primitives  #b4  can do temporal and velocity modulation; however unlike ProMPs, DMPs do not address the inverse problem of estimating the phase itself. Basis functions encode positions which are critical for the tractability of interaction primitives since estimating the forcing function of a human (a DMP requirement) is non trivial. IProMPs where initially presented in  #b3 . The goal of the framework is to enable a robot assistant to adapt and learn new interactive skills on demand. Imitation learning is leveraged in collaboration tasks and ProMPs are used to generate distributions from human motion observations. The distributions serve as a prior model in a lower dimensional weight space. The model is used to recognize the intended motion of the human agent and to generate a movement primitive for the robot. By using the IProMP framework, trajectories from the human and the robot can be naturally correlated thus simplifying the framework's complexity. Maeda et al. extended the IProMP framework to track human movement progress  #b4 . A temporal rescaling factor is estimated through human observations to improve the robot motion regression. The observation however is static. Only a single human-motion observation is used to regress the corresponding robot motion. The system is unable to dynamically adapt its prediction given new observations. More recently in  #b9 , Manschitz et al. enhanced the DMP formulation so as to adapt to different objects. Attractors can be represented in different coordinate frames. They can also continuously activate a set of attractors over time by solving a convex optimization problem. The co-articulation of movements is also supported explicitly. The work however assumes distributions for the entire task which are both timealigned and temporally-modulated. In contrast our robot's adaption to human motions leverages dynamic observation windows (DOWs) that yield sets of possible robot motion distributions. The most likely new robot motion distribution is merged with the existing motion through blending  #b8  to yield continuous, more accurate and more responsive robot motion updates. In this work we study the effectiveness of dynamic observations for human motions in HRI tasks. Our contribution extends Interactive Primitives via the Probabilistic Movement Primitives to use a dynamic time-windows for human observations. Compared with the single fixed-time (static) formulation, our dynamic approach yields anticipatory robot motions with higher accuracies (throughout the trajectory and at the end-pose), temporal responsiveness, and good phase estimation in the robot's motion. We also contribute a metric that aids in the selection of a time-window duration that minimizes positioning and phase estimation errors. Though the re-formulation for dynamic situations is simple, it results in superior responsiveness and accuracy achievements for the robot's anticipatory motions, especially when human motions share similar initial motions but divert later in the task.We use the IProMP framework with phase estimation to model MPs via Gaussian distributions. Human observations are captured through a dynamic time-window whose duration is determined by a parameter (Sec. II-B). Phase estimation is limited to the dynamic window duration (Sec. II-C). Once the human observation is updated based on the human phase, we perform the robot task recognition by selecting the posterior distribution with the highest probability (Sec. II-D). Blending is then performed iteratively for each new dynamic observation (Sec. III). To blend, we co-activate the current distribution with the incoming distribution by computing the product of the distributions as a function of a smooth activation function. Fig. 3 shows how five co-activations occur in a task. The output is a smooth transition for the iteratively updated robot trajectory.In our experiments (Sec. IV) we compare the performance of the dynamic time-window IProMP formulation with that of a static time-window formulation across two experiments: (a) tasks with a uniform trajectory pattern and (b) tasks where trajectories are similar at the beginning of the task but diverge later in the task. For each experiment, we compare accuracy gain as a function of dynamic window-time duration for three measurements: (i) robot joint angle configuration at each time-step, (ii) Cartesian position at the final goal position, and (iii) phase estimation error. Finally, a weighted sum error metric is used to select the most optimal dynamic window time duration across all metrics. In the first experiment, we tests hand-over tasks for three different objects. We vary the duration of the dynamic time-window to study its effect on robot position accuracy as well as phase estimation error. We found that for DOWs, we achieve average accuracies that would only be possible if the static window duration were 90% or more of the human motion. In the second experiment, we test the responsiveness of our system by testing on sets of trajectories that have common paths at the beginning but deviate later on. We found that DOWs yields a much more responsive system; one that is able to adapt correctly in situations where multiple learned human distributions initiate with similar paths but deviate later in the trajectory. Our work thus shows that more accurate and responsive motions can be attained in probabilistic formulations for HRI/HRC by dynamically updating the human observations. Our paper is organized as follows: in Sec. II, we introduce the Probabilistic Motion Primitives framework and its extensions to Interaction Primitives and Phase Estimation. In Sec. III, we explain how blending can be done for dynamic observation settings. Sec. IV presents two experiments and associated results. Finally, in Sec. V we highlight key lessons learned in this work.

II. INTERACTION MOTION PRIMITIVES WITH PHASE ESTIMATION AND DYNAMIC OBSERVATIONS
In HRC tasks, IProMPs generate a robot collaborative motion based on the prediction from a set of partial human motion observations. In this section, we introduce IProMPs by first explaining probabilistic movement primitives for a single dimension. We then expand the case for multiple dimensions and also describe the formulation for interactive scenarios. Later we incorporate phase estimation with dynamic time-window human observations and conclude by explaining parameter learning.

A. Probabilistic Movement Primitives for a Single Dimension
ProMPs summarize patterns across demonstrations in a probabilistic manner. ProMPs capture correlations across data dimensions leading to a probability distribution over trajectories. Representing variance information correctly is critical as it reflects variations in movement execution across time steps. For each time step, a single dimension position is represented by y t ∈ R 1 and a trajectory of T time steps as y 1:T . A parameterization of y 1:T in a lower dimensional weight space is given as as a linear basis function model of n Gaussian basis functions and weights ω according to:y t = ψ T t ω + y , p(y 1:T |ω) = T 1 N (y t |ψ T t ω, σ y ),(1)where, y ∼ N (0, σ y ) models zero-mean i.i.d. Gaussiannoise. The set ψ = [(ψ t ) 1 , (ψ t ) 2 , ..., (ψ t ) N ] T ∈ R N ×1contains values for each of the basis function at time t. Given a basis function, one can compute ω for each trajectory y 1:T using linear regression with a time-dependent design matrix:ω = (Ψ T 1:T Ψ 1:T ) −1 Ψ 1:T y 1:T ,(2)where,Ψ 1:T =     (ψ 1 ) 1 · · · (ψ 1 ) N . . . . . . . . . (ψ T ) 1 · · · (ψ T ) N    (3)The ω vector can compactly represent a single trajectory as the number of basis functions is often much lower than the number of trajectory steps * . Having a set of motion trajectories, we can compute a probability distribution over the weights ω. To capture the variance across trajectories in different demonstrations, we define θ as a parameter that governs the distribution of weight vectors in the set ω and we assume that ω ∼ N (µ ω , Σ ω ), that is θ = (µ ω , Σ ω ). * Handover tasks have an average duration of 4 seconds sampled at 50Hz leading to 200 samples. Instead we use 31 basis functions, thus only using 16% of the original sample sizeThe trajectory distribution p(y 1:T ; θ) can now be computed by marginalizing out the weight vector ω. The distribution p(y 1:T ; θ) defines a Hierarchical Bayesian Model (HBM) whose parameters are given by the observation noise variance σ y and the parameters θ of p(ω; θ). We compute the probability distribution of a position at a given time from the ω distribution as:p(y t |θ) = p(y t |ω)p(ω|θ)dω = N (y t |ψ T t µ ω , ψ T t Σ ω ψ t + σ y ).(4)The above distribution captures spatial correlations across a set of demonstrations. To cope with demonstrations of varying durations the training set is time aligned.

B. Human and Robot Movement Correlations in an Interaction Model
We now extend ProMPs to a multidimensional setting and compute the correlation for the full set of data-dimensions for human and robot motions across demonstrations. One important assumption in this work is that human-motion collaborative-task trajectories differ spatio-temporally from one another. Under such assumption, the use of motion information is sufficient to distinguish distinct tasks. However, if the assumption is violated and different tasks share similar trajectories, the task recognition system will fail. Our work in  #b10  addressed this limitation by leveraging differentiating data such as muscle activity electromyography.IProMPs model the correlation across multiple dimensions. Each dimension is given by each of agent's degreesof-freedom (DoFs). We define the state vector y t as a concatenation of the observed P number of human DoFs, followed by the Q DoFs of the robot:y t = [y H 1,t , ...y H p,t , y R 1,t , ...y R q,t ] T ,(5)where, (.) H refers to the human position and (.) R refers to the robot joint angle configuration. The weight vector ω is the concatenation of all weight vectors involved in a given demonstration. Thus, all the interacting dimensions in a task are correlated as:ω T i = [(ω H 1 ) T , ..., (ω H p ) T , (ω R 1 ) T ..., (ω R q ) T ].(6)As in the single dimension case, the weight vector is given as a linear regression model: p(y t |ω) = N (y t |H T t ω, Σ y ). H t is the time-dependent basis matrix for the human and robot observations and defined as:H t = diag((ψ T t ) 1 , ..., (ψ T t ) p , (ψ T t ) 1 , ..., (ψ T t ) q ).(7)Given partial human observations, the posterior distribution is computed using a Kalman Filter (robot observations are set to zero) yieldingy o t = [y H 1,t , ...y H p,t , y R 1,t , ...y R q,t ] T . Tocontrast with a complete observation sequence [t : t ], the notation [t − t ] ∈ R s×(p+q) is used to indicate a sequence s of partial observations in the interval. Observations can be considered as modulations to via-points. The operation is done by conditioning the ProMPs to reach a certain statey o t−t at time (t − t ). The conditioning adds a desired observation x t−t = [y o t−t , Σ o y] to the probabilistic model and applies Bayes theorem. Kalman filtering is used to compute the posterior distribution according to:µ new ω = µ ω + K(y o t−t − H t−t µ ω ), Σ new ω = Σ ω − K(H t−t Σ ω ).(8)Here, K = Σ ω H T t−t (Σ o y + H t−t Σ ω H T t−t ) −1 .Since missing robot observations exist, for each time step of the observation matrix we set H t−t as:H t−t =            (ψ T t ) 1 · · · 0 0 · · · 0 0 . . . 0 0 . . . 0 0 · · · (ψ T t ) p 0 · · · 0 0 · · · 0 0 1 · · · 0 0 . . . . . . 0 . . . 0 0 · · · 0 0 · · · 0 q            (9) with H t−t ∈ R (p+q)×(p+q)N .

C. Phase estimation with Dynamic Observation Windows
Humans normally execute repetitions of specific tasks at different speeds. This facts leads to uncertainty in the demonstration's time duration. To capture the task's spatial variation correctly, time alignment must be done. Additionally, the phase of human observations (at test time) must be estimated to align it to that of trained spatial models.In Maeda et al. original work  #b4 , each demonstration (which used static observation windows (SOW))was resampled yielding a nominal duration T nom_sow . We adjust the definition of the nominal duration to fit the length of the dynamic observation window (DOW) duration yielding T nom_dow . For each i th demonstration, we assume constant temporal changes in relation to the nominal duration. Eqtn. 10 thus introduces a temporal scaling factor to index demonstrations according to the nominal DOW time index.α i_dow = T i /T nom_dow .(10)To determine the best phase estimate during test time, we use the single phase temporal model in  #b4 . A distribution of phase ratios across demonstrations is modeled as a normal distribution and set as the phase prior: α dow ∼ N (µ α dow , σ α dow ). Given a human observation y o t−t , the phase posterior is:p(α dow |y o t−t , θ) ∝ p(y t−t |α dow , θ)p(α dow ),(11)with p(α dow ) as the prior for scaling factor α dow , and with a task-specific likelihood given by:p(y t−t |α dow , θ) = p(y o t−t |ω, α dow )p(ω)dω.(12)So finally, the best task-specific phase estimate given the human observations y o t−t is:α * dow = arg max α dow p(α dow |y o t−t , θ).(13)In Sec. III-A, we explain how to choose the best duration for the DOW. 

D. Task Recognition
Once the best phase estimate for human observations is obtained, we must recognize the most likely task model in a set of k tasks. Task recognition also follows a probabilistic approach. We compute the posterior distribution of a task given human observations according to:p(k|y o t−t ) ∝ p(y o t−t |θ k , α * dow )p(k),(14)where, p(k) is the task's prior probability and can be determined by the specific circumstances of an experiment. The likelihood of each component given the model θ is:p(y o t−t ; θ k , α * dow ) = p(y o t−t |H o t−t ω, Σ y )p(ω; θ k )dω.(15)A task is selected by choosing the posterior with the highest probability: k * = arg max k p(k|y o t−t ).

III. ITERATIVE BLENDING OF MOVEMENT PRIMITIVES
In this section, we present the mechanics of the iterative combination of different MPs into a single compounded primitive. It is this iterative blending, afforded by the set of distributions produced as a result of dynamic observation widows that set this work apart.Consider a set of i distinct primitives p i . When a new human observation is acquired, a new robot primitive p new is generated. Primitive pairs are co-activated through the product of their distributions:p new ∝ i p i (τ ) a [i], where a [i] ∈ [0, 1] denotes the activation of the i th primitive. The product captures overlapping regions of active MPs.It's also necessary to modulate the activations of primitives to continuously blend the movement execution from one primitive to the next. First, a trajectory is decomposed into single time steps and uses time-varying activation functions a t[i] such that product of distributions is defined as:p * (τ ) ∝ t i p i (y t ) at [i] , p i (y t ) = p i (y t |ω [i] )p i (ω [i] )dω [i] .(16)For Gaussian distributions p i ((y t )) = N (y t |µ[i] t , Σ [i]t ), the resulting distribution p * (y t ) is defined as in  #b8  and is again Gaussian with variance and mean:Σ * t =   i Σ [i] t /a i t −1   −1, andµ * t = (Σ [i] t )   i Σ [i] t /a [i] t −1 µ [i] t   .(17)As for the activation function used in this work we use a pair of sigmoid functions to define a rising edge and a falling edge respectively:a rise [t] = 1 1 + e −lt , a f all [t] = 1 1 + e lt .(18)where, l denotes the gradient of the activation function.

A. Error Metric
In this work we formulate a metric to measure which dynamic observation time-window duration will perform best for in our predictive formulation. Before introducing the metric, we present the performance measurements used in this work and some explanations for how they are measured in the dynamic case and the static case which serves as a baseline.To measure the performance of the dynamic time-window formulation we make use of three measurements: (i) e p Cartesian position final goal accuracy, (ii) e q Joint angle configuration error sum at each time-step, and (iii) e φ Phase estimation error at the goal position. For each of these three measurements we compute the difference between a corresponding ground-truth and the actual goal position. Furthermore, we are interested in computing the performance gains of the dynamic formulation over that of the static one. For each of the three aforementioned measures we compute the difference between the static and the dynamic results i.e.∇e p = e p sow(f ) − e p dow_t ∇e q = e q sow(f ) − e q dow_t ∇e φ = e φ sow(f ) − e φ dow_t .(19)Note that for the static formulation performance is reported according to the observation window percentage (observing an entire task is equivalent to observing 100% of the task) sow(f ). For the dynamic formulation performance is reported according to the duration of the dynamic time window dow_t. Thus to measure the performance gain in the dynamic formulation, we compute the difference in performance for the three measures using observation window percentages (static case) and different curves for dynamic window durations. Fig. 6 from the Experiments section illustrates these measurements.In order to the determine which dynamic observation timewindow duration has the best performance over the three measures, we use a weighted sum of errors to define the total error measurement for a given dynamic window. The weighted error sum result for each dow_t is placed in the rows of column matrix m as shown in Eqtn: 20. Then, the index with the smallest error sum is selected as the best time duration window for a given motion type.min m dow_t = γ p ep dow_t maxt ep dow_t + γ q eq dow_t maxt eq dow_t + γ φ e φ dow_t maxt e φ dow_t(20)where, the weighting scale for each of the three measures is given by γ i , where i = p, q, φ. Each factor represents the fraction of error measure for a given dow_t with respect to the maximum error value across all dynamic window durations.

IV. EXPERIMENTS AND RESULTS
Our experimental testbed used the dual-armed humanoid Baxter robot with standard Rethink Robotics electric grippers. An ASUS Xtion Pro camera was used along with OpenNI tracker in ROS Indigo and Linux Ubuntu 14.04. As for dynamic observation window durations dow_t, this work tested a range of four discrete values: dow_t = [1, 0.5, 0.2, 0.1] secs. The temporal scaling factor α_dow is computed by using a nominal duration T nom_dow set to the duration of the dynamic observation window. Given a dynamic time window duration dow_t, the total number of dynamic observations in a task is then the ratio of task duration to dynamic time window duration: T /dow_t An equivalent number of co-activations are needed to update the robot's motion through the task. Finally, for the dynamic observations, beyond the duration of the window, the number of observations in a given window must be selected. For these experiments, we observed every 1-out-of-5 human joint angle readings.Two distinct experiments are used to test the system performance. The first experiment uses simple trajectories, while the second experiment uses sets of trajectories that share similar starts but have different endings. For each demonstration, a total of 20 trials are executed. Leave-oneout cross-validation (loocv) is used for training and testing. Performance is evaluated under two modalities. First, is a direct evaluation for the dynamic formulation according to the three measures introduced in Sec. III-A. Second, is a comparative evaluation between the dynamic formulation and the static one using the same three measures.

A. Experiment 1
Exp. 1 is designed to test the accuracy of the dynamic predictions. Three collaborative handover tasks consisting of a simple box, a glasses case, and a circular masking tape are conducted as shown in Fig. 5. For each task, the path of the trained human trajectories is unimodal; in other words, all task trials beginning and end paths are the same distribution (in Exp. 2, the ending portion of the trial trajectories diverge in different directions as seen in Fig. 8). Fig. 6, the dynamic formulation achieved average (of dynamic window durations) Cartesian position goal errors of (0.028, 0.023, 0.059)m; average RMS joint errors of (0.163, 0.163, 0.195)rad, and average phase estimation errors of (0.176, 0.203, 0.213)s for the box, glasses, case, and tap handovers respectively.

Results


1) Direct Evaluation: As summarized in
All the best results came from duration 1.0s (except for the phase error which came from the tape task) but notice that the difference between other window durations is not significant. This give us the flexibility to select shorter durations that increase responsiveness at the expense of a small loss in accuracy.2) Comparative Evaluation: Performance comparisons for the dynamic formulation of the handover box between the static and dynamic formulations are summarized in Fig.  7. The figure has three plots for each of the three error measure comparisons. With each plot, four curves represent four distinct dynamic observation window durations. The curves represent the difference between the static and dynamic formulations from Eqtn. 19. A positive error in the graph implies that the dynamic formulation performance outperforms the static one. The top plot, which is related to the Cartesian goal position error difference at the end of the task, shows three of the four curves are almost superimposed. This indicates that the accuracy performance of the dynamic system for durations of 1, 0.5, and 0.2 seconds was similar (ultimately each of these windows will have observed all data). For these three curves it is not until the static system observes around 80% of the trajectory that it can match the performance of the dynamic system. Given that the dynamic system can continuously update its distributions it gives the ability to increasingly approach the ground-truth while improving responsiveness.  With reference to the middle plot, we consider the RMS joint angle configuration error difference along trajectory time steps. Notice that the performance of different dynamic window durations varies in non-trivial ways. The best performance comes from the longest duration window RM S1.00. For this particular curve, the static formulation does not match the performance of the dynamic window as the error difference does not reach zero by the end of the task. The reasoning is the same as that mentioned for the Cartesian goal position measure.With respect to the bottom plot, we consider the Phase estimation error difference at the end of the task. Recall that our scaling factor α dow is set by the duration of the dynamic observation window. The best performance comes from the window P HA1.00. This indicates that longer durations for nominal window durations assist in having better phase estimation errors. The dynamic performance was only matched by the static formulation when it observed slightly less than 70% of the trajectory.Given these three independent error measure comparisons, we must determine which dynamic observation window performed best across all measures. Using the metric definition in Eqtn 20, we tested two γ weight combinations {{0.33,0.33,0.33}, {0.50,0.25,0.25} * } for our performance metric m. In all cases, dynamic observation window with 1.0 second duration had the best performance. The results from the box handover case were consistent with the results for the glasses case demonstrations and the tape demonstrations. The dynamic formulation reported similar gains across all measures. * And all combinations of this set. 

B. Experiment 2
In Exp. 2 we test the performance of the system, through the use of four handover tasks that share similar initial trajectories but in the end diverge to leftwards, rightwards, upwards, and downwards as depicted in Fig.  8. As in Experiment 1, we perform direct evaluations and comparative evaluations. We also compare the performance of dynamic formulation in Exp. 2 with that in Exp. 1. Fig. 8. Collaborative trajectories with similar human initial paths and diverging paths. The red color indicates one collaborative task, the green another one. By using static observations in the first half of the trajectory the predictive system have no better results than chance to predict the correct final position. The static system would also lack responsiveness to the changes effected by the human collaborator later in the task.  2) Comparative Evaluation: The comparative evaluation between the dynamic and static formulations is more complicated given that we have 3 tasks in Exp. 1 and 4 in Exp. 2 and we are considering the 4 window durations and the observation ratios for the static case. As with our direct evaluation, we resort to presenting average results and commenting in interesting cases. As in Exp. 1, Fig.  9, presents the comparative performance between average static results and average dynamic results. These results are the average of 20 loocv, including situations in which the static formulation both correctly and incorrectly classified the task. In fact, task recognition rates for the static formulation across observation ratios is shown in Table II. Evidently,  better, as would be expected, but the main factor is that the performance of the other windows was almost the same making it possible to gain responsiveness for a small loss in accuracy. Finally and most importantly is the fact that the static distribution begins with large errors in the first half of the observations and only later registers quick error drops when it is able to observe more than half of the human trajectory.

1) Direct Evaluation:
As for Cartesian goal position error difference at the end of the task, the static formulation begins with error differences of 0.1m. The average performance of the dynamic formulation was 0.04m: the difference is more than double. Hence, particularly at the beginning, the static formulation struggles to correctly classify the true trajectory and generates motion that has more than double the inaccuracy of the average of the dynamic formulation. As for the RMS joint angle error, the same story occurs here. An error difference larger than 0.3rad occurred. Again almost double the average value for the dynamic formulation which yielded 0.14rad. As for the phase estimation error, the error difference was 0.13s. The average performance of the dynamic formulation was 0.17s. A negligible difference for most human tasks.

V. DISCUSSION AND CONCLUSION
This work showed that when the IProMP framework with Phase Estimation is deployed with dynamic human observation windows the accuracy of the predictive generated robot motions increase significantly from the very beginning. In the same way, the dynamic formulation offers a much more significant responsiveness in its anticipatory motions. Hence, the robot generates motion that is constantly adapting smoothly to the human's motion. Our results were tested across a wide variety of motions and objects, including instances where trajectories begin with similar motions and end with diverging ones-not unlike natural human movements. The approach still suffers from appropriate robot motion generation if the observation was not included in training. We are considering the idea of projecting existing probabilistic distributions to newly observed spaces if we are confident the task type is similar. Also, sometimes the predicted motion reaches the limits of a robot's arm workspace. In this case, we are considering querying the other robot arm to successfully complete the task.