Deep Neural Network Compression for Aircraft Collision Avoidance Systems

Abstract
One approach to designing decision making logic for an aircraft collision avoidance system frames the problem as a Markov decision process and optimizes the system using dynamic programming. The resulting collision avoidance strategy can be represented as a numeric table. This methodology has been used in the development of the Airborne Collision Avoidance System X (ACAS X) family of collision avoidance systems for manned and unmanned aircraft, but the high dimensionality of the state space leads to very large tables. To improve storage efficiency, a deep neural network is used to approximate the table. With the use of an asymmetric loss function and a gradient descent algorithm, the parameters for this network can be trained to provide accurate estimates of table values while preserving the relative preferences of the possible advisories for each state. By training multiple networks to represent subtables, the network also decreases the required runtime for computing the collision avoidance advisory. Simulation studies show that the network improves the safety and efficiency of the collision avoidance system. Because only the network parameters need to be stored, the required storage space is reduced by a factor of 1000, enabling the collision avoidance system to operate using current avionics systems.

I. INTRODUCTION
Decades of research have explored a variety of approaches to designing decision making logic for aircraft collision avoidance systems for both manned and unmanned aircraft  #b0 . Recent work on formulating the problem of collision avoidance as a partially observable Markov decision process (POMDP) has led to the development of the Airborne Collision Avoidance System X (ACAS X) family of collision avoidance systems  #b1 ,  #b2 ,  #b3 . The version for manned aircraft, ACAS Xa, is expected to become the next international standard for large commercial transport and cargo aircraft. The variant for unmanned aircraft, ACAS Xu, uses dynamic programming to determine horizontal or vertical resolution advisories in order to avoid collisions while minimizing disruptive alerts. ACAS Xu was successfully flight tested in 2014 using NASA's Ikhana aircraft  #b4 .The dynamic programming process for creating the ACAS Xu horizontal decision making logic results in a large numeric lookup table that contains scores associated with different maneuvers from millions of different discrete states. The table is extremely large, requiring hundreds of gigabytes of  score table is to downsample the table after dynamic programming. To minimize the degradation in decision quality, states are removed in areas where the variation between values in the table are smooth. The downsampling reduces the size of the table by a factor of 180 from that produced by dynamic programming. For the rest of this paper, the downsampled ACAS Xu horizontal table is referred to as the baseline, original table.Even after downsampling, the current table requires over 2GB of floating point storage, too large for certified avionics systems  #b5 . Although modern hardware can handle 2GB of storage, the certification process for aircraft computer hardware is expensive and time-consuming, so a solution capable of running on legacy hardware is desired  #b6 . While there is no formal limit for floating point storage on legacy avionics, a representation occupying less than 120MB would be sufficient.For an earlier version of ACAS Xa, block compression was introduced to take advantage of the fact that, for many discrete states, the scores for the available actions are identical  #b7 . One critical contribution of that work was the observation that the table could be stored in IEEE half-precision with no appreciable loss of performance. Block compression was adequate for the ACAS Xa tables that limit advisories to vertical maneuvers, but the ACAS Xu tables for horizontal maneuvers are much larger. Recent work explored a new algorithm that exploits the score table's natural symmetry to remove redundancy within the table  #b8 . However, results showed that this compression algorithm could not achieve sufficient reduction in storage before compromising performance.Discretized score tables like this can be represented as Gaussian processes  #b9  or kd-trees  #b10 . Decision trees offer a way to compress the table by organizing the data into a tree structure to remove table redundancy. In addition a decision tree can increase compression by simplifying areas of the table with low variance, although this will result in a lossy compression. Decision trees are a popular machine learning algorithm and have been applied to numerous problems including land cover classification and energy consumption prediction  #b11 ,  #b12 .Other approaches to compressing the table seek to find a robust nonlinear function approximation that represents the table. Linear regression is popular for smaller datasets, but this approach does not generalize well for large datasets with many more examples than features. Support Vector Machines (SVM) are also a popular regression algorithm. By storing only the supporting vectors found by the algorithm, less data would need to be stored, effectively compressing the dataset.However, SVMs struggle with large datasets. Solving the SVM quadratic program has computational cost that scales at least with the square of the number of examples  #b13 . Because the ACAS Xu table has millions of entries, SVMs would not be  effective in regressing the score table. Neural networks, which can serve as a robust global function approximator when trained using supervised learning, can represent large datasets and are trained efficiently. Neural networks have been employed for regression applications in the aerospace field since the 1990s, including aircraft control systems, aircraft design, and impact detection on structural panels  #b14 ,  #b15 ,  #b16 . These applications use datasets with only a few hundred training examples, so small neural networks with one or two hidden layers are effective. However, to accurately represent 2GB of floating point values, a larger network is required.Recent works have shown that deep neural networks, or neural networks with more than two hidden layers, represent data more efficiently than shallow networks. It can be shown that the number of linear regions represented by neural networks grows exponentially with the depth and polynomially with the layer size, so a deeper network can represent more information than a shallow network  #b17 . In addition, it was shown that a three-layer network cannot be approximated by a two-layer to arbitrary accuracy unless the layer size is expanded exponentially  #b18 . Previously, neural networks were limited in depth due to activation saturation problems when using sigmoid activation functions  #b19 , but a new piecewiselinear activation function, rectified linear units (ReLUs), were shown to be well suited for training deep neural networks  #b20 . These advancements enable neural networks to efficiently regress large amounts of data like the ACAS Xu collision avoidance table.This paper explores the use of deep neural networks for compressing the score table without loss of performance as measured by a set of safety and operational metrics. Using an asymmetric loss function during training ensures that the approximation is able to maintain the actions recommended by the original table while providing good estimates of the original score table values, but the required runtime is significantly increased. Methods for eliminating the runtime increase are explored that lead to an approach that produces advisories more quickly than the original table. Further studies into finetuning the network training process enable the neural network to predict table values with even greater accuracy.Standard safety and operational performance metrics were used to evaluate the network performance in simulation. These metrics are calculated by simulating millions of encounters with varied encounter geometries and sensor noise. Although the deep neural network reduces the required memory by a factor of 1000, it also improves the performance of the ACAS Xu system on most performance metrics evaluated in this paper with only one operational metric slightly degraded. The neural network representation is a continuous function that smooths out artifacts from interpolation of the original discrete representation, allowing the network to surpass the system it was trained to represent.Section II provides an overview of the score  The first five state variables describe the geometry of a 2D encounter between two aircraft, as seen in Fig. 1. In addition, τ describes the encounter geometry vertically and extends the encounter geometries to 3D. Lastly, a prev specifies the previous advisory to enable consistency when choosing the next advisory. The state variables are discretized, forming a seven dimensional grid with 120 million discrete points.The optimal advisory for a given state can be extracted from the score table. If Q is the real-valued function associated with the eight-dimensional score table, then the optimal action isa * = arg max a Q(ρ, θ, ψ, v own , v int , τ, a prev , a)(1)Furthermore, Equation (1) defines the score table's policy by mapping all possible states to actions. In general, the values of the state variables, as determined by the sensors in real time, do not fall exactly on the grid points, in which case nearest-neighbor interpolation is used.Since the surveillance sensors used by the aircraft are imperfect, there may be uncertainty in the current state measurement. To improve the robustness of the system to this uncertainty  #b21 , ACAS Xu uses an unscented Kalman filter  #b22  to arrive at a set of weighted state-space samples. These weighted samples can then be used to compute the best action:a * = arg max a i b(s (i) )Q(s (i) , a)(2)where s (i) is the ith state sample and b(s (i) ) is its associated weight.Although the state space specifies an encounter with a single intruder, multi-intruder encounters can use the same collision avoidance table by using utility fusion  #b3 . The action scores can be computed for each intruder and then fused into a single action by considering only the worst-case intruder or by summing the action scores for each intruder and taking the action with the best score  #b3 . Therefore, representing the collision avoidance policy as action scores allows the single intruder policy to be extended to multi-intruder scenarios.

III. BASELINE TABLE REGRESSION METHODS
With 600 million floating point numbers, the table requires over 2GB of storage. Compression algorithms that exploit table symmetries to reduce redundancies could not adequately compress the large score table  #b7 ,  #b8 . As a result, machine learning algorithms for lossy compression were explored.Linear regression works well for small datasets, but with 120 million training examples and only seven features, a linear mapping from features to output values will be too simple to be accurate. Linear regression approximates the table values asŷ = XW , where the weights W can be optimized to minimize the squared error using W = (X T X) −1 X T y. After calculating the weights, the root mean squared error (RMSE) is 17.9, which is approximately the standard deviation of the table values. A more complex model is necessary for this application.Although Support Vector Machines (SVM) can represent complex data, SVMs regress very slowly for large datasets, rendering them a poor choice for this application with a large number of training examples  #b13 . Image compression algorithms like JPEG2000 or Huffman encoding can enable efficient storage and transmission of data files, but the data will have to be uncompressed and loaded into memory at runtime. Furthermore, the entire dataset must be loaded into memory to enable multi-intruder tracking, so the compressed representation must efficiently represent the entire table.With these considerations, decision trees are the best alternative to a neural network approach. Decision trees are a popular regression algorithm and work well given large data sets. The size of the decision trees can be controlled by setting a maximum depth of the tree. At each level in the decision tree, an input variable is compared with a threshold, splitting the table data into two different sets. These decision nodes are chosen to minimize the variance in the split datasets through use of the Gini impurity  #b23 . The algorithm begins by determining the root decision and then builds the tree layer by layer until the maximum depth is reached. The final layer is composed of leaf nodes, which store the average scores of the data in the leaf node. When making a prediction, a new state is passed through the decision tree, splitting at each decision node until arriving at a leaf node where the stored values become the predicted values.The amount of storage required to represent the decision tree can be computed by multiplying the number of nodes in the tree with the size of each node. Decision nodes will need to store the decision feature and threshold as well as pointers to children nodes, while leaf nodes will need to store the estimated table values. While larger trees can represent the score table more accurately, they require more storage. The Scikit-learn machine learning library was used to create decision trees for the ACAS Xu score table  #b24 .One way to assess the quality of the compression is to plot the actions recommended by the original table and the compressed strategies. Because the input space is seven dimensional, the plots only show variations in ρ and θ, which are converted to Cartesian coordinates, while the other inputs are constant. Figure 2 shows top-down views of encounters with the ownship centered at the origin and flying in the direction indicated while the intruder vehicle is flying in the direction shown by the aircraft in the upper right corner of the plots. The color at each point in the plot shows the advisory the collision avoidance system would issue if the intruder were at that location. Figure 2 shows the policy plots of regressed decision trees of different sizes. Increasing the maximum depth improves accuracy, although there are still errors between the decision tree and original policy.In addition, aggregate metrics were computed to assess compression quality. The decision trees can be used to predict the scores for every discretized state represented by original table. By comparing the predicted scores with the original table scores, the root mean squared error (RMSE) of the values can be computed. In addition, the overall policy error is calculated using Eq. (1) and comparing the optimal actions of the decision tree and original table. The tradeoff between tree size and compression error is plotted in Fig. 3. Using decision trees that are at most 100 MB in size, the RMSE exceeds 3.0 with a policy error rate of over 6%, which could result in significant changes to system performance. By contrast, the neural network representation, as discussed in the remainder of this paper, can accurately represent the table values with only 2.4 MB of storage.

IV. NEURAL NETWORK COMPRESSION
This section explains the development of a deep neural network approximation of the score table.

A. Neural Network Formulation
Rather than storing all of the table scores explicitly or using a tree approximation, the values of the table can be represented  as a nonlinear, parametric function that takes as input the values of the state variables and outputs the scores of the various actions. Instead of storing the table itself, only the parameters of the function need to be stored, which could significantly decrease the amount of storage required to represent the table. Deep neural networks are large, nonlinear functions that can be trained to approximate complex multidimensional target data  #b25 . A feed-forward neural network is composed of inputs that are weighted and summed into a layer of perceptrons. The value at each perceptron then passes through an activation function before being weighted and summed again to form the next layer of perceptrons. In a deep neural network, there are multiple layers, called hidden layers, before reaching the last layer, or output layer, which represents the function approximation for the score table. The weights and biases of the network can be trained so that a given set of inputs will accurately compute the score table values. The choices of the neural network architecture and features can help the network to train quickly and accurately. Figure 4 shows an example diagram of a fully-connected network with two hidden layers and rectified linear unit activations (ReLU)  #b26 , which only allow positive inputs to pass through to the next layer.The deep neural network uses fully-connected feed-forward layers with ReLU activation after each hidden layer. The network has seven inputs, one for each of the seven state variables. The output layer consists of five output nodes, one for each possible advisory: Q COC , Q WL , Q WR , Q SL , and Q SR . With this approach, one forward pass through the network computes the score values for each of the five advisories.

B. Loss Function
Initially, the network parameters are random, and the network performs poorly. A loss function is used to compute the network error, and the gradient of the loss is backpropagated through the network to update network parameters and improve performance. For typical regression problems, mean squared error (MSE) is used because it is simple, differentiable, and fast to compute. When applied to the problem of learning score table values, MSE gives accurate approximations. However, there is no longer a guarantee that the optimal advisory remains the same. For many of the states in the score table, the difference between the scores of the first and second best advisories is relatively small. When MSE fails to maintain the order of the actions, the network's collision avoidance strategy can be very different from that of the original table.Predicting the optimal action given a set of inputs is a classification problem often solved with categorical cross entropy loss  #b28 . This approach can predict optimal actions well, but there is no regard for representing the score values. It is important to capture the score values too in order to compute the optimal advisory over a weighted set of states using Eq.  #b1 .To get the numeric accuracy of MSE with the classification accuracy of categorical cross entropy, an asymmetric version of MSE was used. Asymmetric loss functions have been used to train neural networks when positive or negative errors are not identical  #b29 . The asymmetric loss function for collision avoidance, shown in Fig. 5 is based on MSE, but it increases the penalty by a factor when the neural network under-estimates the score of optimal advisories or over-estimates the score of sub-optimal advisories. The factor applied to the optimal advisory is four times greater than the suboptimal advisories to balance the fact that there are four sub-optimal advisories for every optimal advisory. Because the network parameters are updated to minimize the loss, the neural network attempts to eliminate any errors in the score predictions. If the network predictions have small errors, the asymmetric loss function encourages the network to overestimate the scores of the optimal advisories while underestimating the scores of suboptimal advisories, which will not change the policy when using Eq. (1). Therefore, the asymmetric loss function encourages the neural network to maintain the optimal advisories of the score table while also learning accurate representations of the table values. The advantage of the asymmetric loss function over regular MSE can be visualized through the confusion matrices shown in Fig. 6. Each row is normalized to add up to 100% and represents the percentage of states where the neural network selected a particular advisory given the advisory of the original The entries on the main diagonal represent the percentage of advisories correctly classified by the neural network, while the off-diagonal entries show mis-classifications. For the turning advisories, the asymmetric loss function is much better at maintaining advisories and achieves on-diagonal percentages of 90-94% while the nominal MSE loss function maintains advisories only 72-74% of the time.

C. Model Architecture
Optimizing the network architecture can be challenging because there are many parameters to vary and evaluation of the different architectures can be slow. One important consideration in training deep neural networks is to select and tune the optimizer used to update the parameters and weights of the network. Different optimizers were evaluated including RMSprop  #b30 , Adagrad  #b31 , Adadelta  #b32 , and Adam  #b33 . A variant of Adam, known as AdaMax  #b33 , proved to learn the quickest without becoming stuck in local optima. In addition, AdaMax requires relatively little tuning of parameters because it uses estimates of the lower-order moments of the gradient to anneal the step size of the gradient descent  #b33 .After selecting AdaMax for the optimizer, different network architectures were investigated. A baseline architecture was chosen with five hidden layers and a set of layer sizes that is larger early in the network and tapers to smaller layer sizes towards the end of the network. This approach allows for the network to find increasingly more abstract representations of the data, similar to the approach with convolutional neural networks in image classification  #b25 . The layer sizes were also chosen so that the total number of parameters in the network would be around 600,000, as this would mean the table could be compressed to occupy only a few megabytes when using floating point precision. To test the baseline architecture, the number of hidden layers was varied to see the effect on the regression performance, but six hidden layers proved to give the best results with additional layers yielding little improvement. Figure 7 shows the network loss during training for the different network optimizers and number of layers. As a result of this study, a neural network with six hidden layers and AdaMax optimization was chosen. 

D. Implementation
The deep neural network was trained in Python using the Keras library  #b34  running on top of Theano  #b35 . To reduce training time, the deep neural network was trained using an NVIDIA DIGITS DevBox with four Titan X GPUs. Before training, the score table and inputs were normalized to have zero mean and unit range, which helps the network train more quickly  #b36 . For each training epoch, the table data was shuffled and passed through the network in batches of 2 16 samples. The network was trained for 1200 training epochs over the course of four days.  Figure 8 illustrates that increasing τ shrinks the strong alerting region because the aircraft have greater vertical separation, and changing a prev to WR yields a policy that favors right turns in order to reduce reversals. Qualitatively the plots show that the neural network is a continuous approximation of the discrete  of 2.02%, which is lower than all but the largest baseline decision trees shown in Fig. 3. Given that the neural network requires only 2.4 MB of floating point storage, the neural network method is an efficient and accurate compression approach.

E. Results
To evaluate operational performance of the neural network, the network was evaluated in 1.5 million simulated 3D encounters with varied encounter configurations and sensor noise. Overall performance metrics were computed from the simulation results that quantify the overall safety and efficiency of the system. Four performance metrics were considered with the desire to minimize all four metrics: 1) P(NMAC): the probability of a near mid-air collision 2) P(Alert): the probability that the system will give an alert 3) P(Reversal): the probability that the system will reverse the direction of its advisory 4) Relative Runtime: required runtime to compute an advisory, normalized to the original score table The aggregate results from the simulations are shown in Table I. The neural network outperforms the table in the three performance probability metrics. However, due to the large amount of computation required to compute the score values using the deep neural network, the runtime is increased by a factor of 50. This is a significant increase that is addressed in the next section.In addition the score table was modified to optimize for a new parameter: P(Split), the probability that the turning alerts given by the system will be split by COC advisories. This behavior is undesirable because the system alerted that the encounter was clear of conflict before the threat was finished. It was found that the existing score table had issues with large numbers of split advisories, so the values were updated to address this issue. As a result, the neural networks presented in the remainder of this work use the updated table and optimize for P(Split). V. IMPROVING NETWORK RUNTIME As described in the previous section, a large increase in runtime is a significant drawback of the neural network compression. Although each forward propagation requires an average of 0.6 ms of computation on a modern computer, this computation will be performed on slower legacy avionics systems. In addition, multiple states in a weighted set must be evaluated, and look-aheads to determine duration of an advisory further increase the number of evaluated points. Furthermore, the system must be able to handle encounters where up to 30 intruders are present, which means hundreds of forward propagations and any additional computation must be able to run within the allotted one second between advisories. To enable the neural network to run in real time in the most stressing scenarios, the increase in computation time must be eliminated. This section presents two methods for reducing required runtime of the neural network.

A. Network Pruning
The first approach to speed network evaluations reduces the number of computations performed by the network by making the network sparse. Experiments in making computer vision networks sparse show that 90% of network connections can be removed without degrading network performance  #b37 . If similar results can be achieved on the ACAS Xu networks, then runtime required can be reduced by up to a factor of 10, though the actual speedup factor will be lower due to overhead associated with a sparse representation. Although this speedup is not enough to entirely eliminate the runtime increase, this could still contribute significantly to runtime reduction.Pruning the networks is an iterative process that removes a small fraction of the network connections and then retrains the network to adjust the remaining connections. Removing too many connections at once could have a serious impact on the network's performance, so this implementation removes only 2% of the network connections at a time. In addition, The RMSE and policy error rates are plotted as a function of pruning in Fig. 9. With 60% of connections pruned, the RMSE and policy error rate have both doubled, and further pruning increases the network errors. In addition, plotting the pruned policies demonstrates how pruning affects the network. Figure 10 shows the policy plot of a head-on encounter. The policy changes seen in Fig. 9 are sporadic and global, which is expected for a neural network where weight changes in early layers can have an impact on all values in future layers. While pruning 40% of the connections yields only minor policy changes, there are more significant changes when 60% is pruned. If pruning increases to 80%, the policy changes drastically, and likely the performance of the 80% pruned network will be degraded. Therefore, the network can be pruned up to 60% of the network weights before seeing major changes in the policy. This result suggests that the ACAS Xu networks are dense compared to computer vision networks. Due to the additional overhead for using a sparse representation, pruning only 60% of weights will not achieve much speedup, so another approach will be required.

B. Multiple Small Neural Networks
The second method for speeding up network computation uses an array of smaller networks rather than one large network. The training data of the neural network can be divided such that each network approximates distinct parts of the state space. Only one of the small networks is used to evaluate each state, which leads to a runtime speedup. The training data was split into 45 separate datasets by using the 45 different combinations of τ and a prev , and a separate network was trained on each dataset. Because the networks are trained on a factor of 45 less data, the networks can be made smaller, and smaller networks require less computation. To fully eliminate the fifty-fold runtime increase, the networks were made approximately 50 times smaller. Some degradation to performance might be expected, since the networks can no longer generalize between τ and a prev , but as shown in this paper, performance does not degrade much. An example policy plot is shown in Fig. 11, which shows that the smaller networks can approximate the table well. The small networks have 6 hidden layers of 45 hidden units each, giving each network approximately 11000 parameters. Since the total number of parameters in all 45 networks is approximately the same as the single large network, this approach will not increase the memory or storage requirement. Furthermore, training time required for each network is much smaller than training a single large network. Training each network requires approximately 2 hours, and because each network is trained separately, the networks can be trained in parallel on all available GPUs. With four Titan X GPUs, training a new batch of networks can be done in a day, which is also an improvement over training a single large network. This method results in an overall runtime speed up of 3% over the original table runtime, so the network pruning technique was not used.

VI. IMPROVING NETWORK TRAINING
After training the array of small networks, simulations were conducted to compute the overall performance metrics. As reported in Section VII, the performance of the network in simulation shows more work is required to improve the neural network compression. This section presents two methods for improving the quality of the network training data. These adjustments do not change the overall score values the network attempts to represent, but instead finds ways to make the data easier to represent in a neural network format.

A. Removing Table Discontinuity
Although neural networks work well as universal function approximators, for a limited network size, some target data is easier to regress. For example, using a neural network to regress data with large discontinuities will generate more loss than smooth target data because networks represent continuous functions. If large discontinuities are present, more connection weight and neuron activations will be required to produce the large jump, and this might disrupt the network's performance for other areas of the state space. Removing such discontinuities will allow the neural network to achieve better performance on the entire data set.When regressing the score table, large jumps in score values were found that make network regression more error prone.When a prev is not COC, and projected straight trajectories of both aircraft results in minimum separation under 4000ft at the closest-point-of-approach (CPA), an additional penalty is added to the COC action. This penalty prevents the system from ending alerts too early when the aircraft are still on course for collision. While other penalty functions used to generate the score table spread to nearby states and create smooth changes in score values, this penalty does not. If the COC action is taken, then the next time step's a prev will be COC, and the penalty will not be applied again. As a result, the penalty does not spread to neighboring states and remains within the region in which it is applied. Figure 12 plots the original table's COC score value in a similar plot to the previous policy plots. The figure is a topdown plot with the ownship at the origin and the intruder traveling perpendicular to the ownship. At each point in the first two plots, the value of the COC action is shown. The original table has a dark band extending outwards, which represents the states where this COC penalty was applied. In states far away from the intruder, the COC score outside the band is approximately zero, while the values in the band are at most -15.0. The result is a large discontinuity in the value function that is problematic for neural network regression. As shown in the middle plot in Fig. 12, the neural network does not represent the band well, especially far away from the ownship. The rightmost plot shows the error in the neural network representation, and it is clear there are large errors throughout the plot.One solution to this issue is to remove the COC penalty from the network training data and apply the penalty to the network output values. Because the penalty does not spread to other states in the score table, the penalty can be easily removed and reapplied by computing the minimum distance at CPA (d CPA ) and time to CPA (t CPA ) asdx = v int cos(ψ) − v own (3) dy = v int sin(ψ)(4) t CPA = (−r cos(θ)dx − r sin(θ)dy)/(dx 2 + dy 2 ) (5) x = r cos(θ) + t CPA dx (6) y = r sin(θ) + t CPA dy(7)d CPA = x 2 + y 2(8)The COC score when the penalty is removed is shown in the left plot of Fig. 13, which shows that the band of low score values seen in Fig. 12 has been removed. As a result, the network trained to represent this score table is a better fit, as shown in the rightmost plot of Fig. 13. Even the neural network values at close range are more accurate. Because the training data is more easily represented in some parts of the state space and neural networks are global approximators, the entire score table is regressed more accurately. Figure 14 shows the filtered table and neural network policies when the COC penalty is added back to the COC score. The table and network policies match well, yet the simulation results still show more reversals than expected when using the network. Further investigation revealed that the table values are modified using online costs before being used in the system. The online costs deterministically modify the table values used in the collision avoidance system, allowing a designer to tune the system and optimize performance. One important online cost decreases the score of COC and weak turning advisories when the previous advisory is a strong turning advisory, which is applied to prevent the system from ending strong alerts too early. If the system stops alerting too early, then the system may need to alert again in the future, which will lead to split advisories and possibly reversals. The left two plots of Fig. 15 shows the table and neural network policies when the online costs are applied. While the table's policy changes to increase the area of strong alerts around the ownship, the neural network does not change as much. As a result, the online costs cannot tune the neural network performance like the original table, and the neural network is likely to see more reversals and split advisories.

B. Training with Online Costs
The inability of the neural network to change its policy with online costs results from the loss function used to optimize network weights. The asymmetric mean squared error loss encourages the network to under-estimate the scores of suboptimal actions and over-estimate the score of the optimal action. As a result, the score gap between the optimal action and next best action widens, which makes the network policy more difficult to change with online costs. A simple solution to this issue is to calculate the desired policy from the table with online costs added, and then use this policy to determine the optimal action when calculating the network loss. When the network is trained with this approach, the resulting network policy with online costs applied better matches the table policy, as seen in the right plot of Fig. 15.

VII. RESULTS
To evaluate the neural network with new performance metric measuring the probability of split advisories, P(Split), the table and neural network were simulated with an encounter set of 10 million 3D encounters with different encounter geometries and sensor noise. Table II shows a comparison of the performance metrics for the different neural networks considered in this paper. With each update to the neural network compression method, the overall neural network performance   Figure 16 shows top-down views of trajectories taken by aircraft in two example encounters, and although the advisories are horizontal, the vertical separation between the ownship and intruder aircraft is considered by the system through the τ parameter. The intruder aircraft follows its own flight path while the ownship follows either the table or neural network collision avoidance system. The advisories given by the collision avoidance systems are represented by the arrows. In the first encounter, the neural network collision avoidance system alerts the ownship seven seconds earlier than the score table, which allows the aircraft to avoid a near mid-air collision. In the second encounter, the neural network chooses a different turning direction than the score table and avoids a near mid-air collision. As a continuous function, the neural network learns a better interpolation than the nearest-neighbor interpolation used by the original score table, allowing the network to outperform the original table in some cases.The neural network collision avoidance system is also effective in multi-intruder scenarios through utility fusion, which combines the individual decisions when each intruder is considered separately to generate an overall decision for the ownship  #b3 . Figure 17 shows an example scenario with ten aircraft all using the neural network collision avoidance policy. The aircraft positions and velocities are randomly initialized and commanded to fly straight unless the neural network alerts the aircraft to turn. The aircraft fly for 80 seconds, and all ten aircraft are safely routed around each other with a minimum separation of 5564 ft. A few aircraft experience reversals in their turning direction as collisions with different intruders become more imminent, illustrating that the neural network can safely maneuver aircraft through multi-intruder encounters.While simulations can check the network performance in millions of states, simulations are not enough to guarantee the network will behave correctly in all possible states. One method for verifying the neural network representation is to use formal methods to prove properties about the network. The Reluplex algorithm represents neural networks with ReLU activations as a system of equations and uses a simplex method to find a set of inputs to satisfy a desired output constraint  #b38 . If no set of inputs can be found, then it is guaranteed that no set of inputs exist that satisfy the condition. This approach can be used to verify that the network will always alert if an intruder is nearby, for example. The use of neural networks in safetycritical certified avionics is unprecedented, but future work with Reluplex could provide a method for verification and certification of neural networks in aircraft collision avoidance systems.

VIII. CONCLUSIONS
The unmanned variant of the Airborne Collision Avoidance System X (ACAS Xu) makes decisions using an optimized score table, but the table is too large to be used in current avionics systems. A deep neural network representation was trained to approximate the table, maintaining optimal advisories while also approximating table values. Simulation shows that the compression algorithms perform as well as the original table. By factoring the table into subtables to train multiple small networks, the network's required runtime was reduced to the level of the original table lookups. By investigating areas of the state space where the networks represent the table poorly, the network training was modified to allow the network to train more easily, resulting in a more accurate representation of the original table. The neural network representation can be used in place of the original table without degrading performance, enabling the collision avoidance system to be used in existing avionics hardware. If avionics systems with greater storage capacity become available, then this neural network compression approach will allow an even larger and more complex collision avoidance policy to be efficiently represented.