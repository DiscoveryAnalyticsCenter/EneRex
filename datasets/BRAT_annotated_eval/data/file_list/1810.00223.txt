GENERALIZED MULTICHANNEL VARIATIONAL AUTOENCODER FOR UNDERDETERMINED SOURCE SEPARATION

Abstract
This paper deals with a multichannel audio source separation problem under underdetermined conditions. Multichannel Non-negative Matrix Factorization (MNMF) is one of powerful approaches, which adopts the NMF concept for source power spectrogram modeling. This concept is also employed in Independent Low-Rank Matrix Analysis (ILRMA), a special class of the MNMF framework formulated under determined conditions. While these methods work reasonably well for particular types of sound sources, one limitation is that they can fail to work for sources with spectrograms that do not comply with the NMF model. To address this limitation, an extension of ILRMA called the Multichannel Variational Autoencoder (MVAE) method was recently proposed, where a Conditional VAE (CVAE) is used instead of the NMF model for source power spectrogram modeling. This approach has shown to perform impressively in determined source separation tasks thanks to the representation power of DNNs. While the original MVAE method was formulated under determined mixing conditions, this paper generalizes it so that it can also deal with underdetermined cases. We call the proposed framework the Generalized MVAE (GMVAE). The proposed method was evaluated on a underdetermined source separation task of separating out three sources from two microphone inputs. Experimental results revealed that the GMVAE method achieved better performance than the MNMF method. Index Terms-Underdetermined source separation, Multichannel non-negative matrix factorization, Multichannel audoencoder

INTRODUCTION
Blind source separation (BSS) refers to a problem of separating out individual source signals from microphone array inputs where the transfer functions between the sources and microphones are unknown. The frequency-domain BSS approach allows the utilization of various models for the time-frequency representations of source signals and/or array responses. For example, Independent Vector Analysis (IVA)  #b0  #b1  offers a way of jointly solving frequency-wise source separation and permutation alignment under the assumption that the magnitudes of the frequency components originating from the same source are likely to vary coherently over time.Other approaches involve multichannel extensions of Nonnegative Matrix Factorization (NMF)  #b2  #b3  #b4  #b5  #b6 . NMF was originally applied to music transcription and monaural source separation tasks  #b7  #b8  where the idea is to interpret the power spectrogram of a mixture signal and approximate it as the product of two non-negative matrices. This can be viewed as approximating the power spectrum of a mixture signal observed at each time frame by the sum of basis spectra scaled by time-varying magnitudes. Multichannel NMF (MNMF) is an extension of this approach to a multichannel case that allows for the use of spatial information. It can also be seen as an approach to frequency-domain BSS using spectral templates as a clue for jointly solving frequency-wise source separation and permutation alignment.The original MNMF  #b2  was formulated under a general problem setting where sources can outnumber microphones and a determined version of MNMF was subsequently proposed in  #b3 . While the determined version is applicable only to determined cases, it allows an implementation of a significantly faster algorithm than the general version. The determined MNMF framework was later called Independent Low-Rank Matrix Analysis (ILRMA)  #b6 . The MNMF framework including ILRMA is notable in that the optimization algorithm is guaranteed to converge, however, one limitation is that it can fail to work for sources with spectrograms that do not comply with the NMF model.To address this limitation, a technique called the Multichannel Variational Autoencoder (MVAE) method was recently proposed in  #b9 . It is an extension of ILRMA in which a Conditional VAE (CVAE)  #b10  is used instead of the NMF model to estimate the power spectrograms of the sources in a mixture. Specifically, MVAE allows the estimation of the separation matrices by employing a single CVAE, trained using the spectrograms of speech samples with speaker ID labels, as a generative model of the speech spectrograms of multiple speakers. This approach is noteworthy in that it can exploit the benefits of the representation power of DNNs for source power spectrogram modeling and has shown to outperform ILRMA on a determined source separation task.While the original MVAE method was formulated under determined mixing conditions, this paper generalizes it so that it can also deal with underdetermined cases. We call the proposed framework Generalized MVAE (GMVAE) to distinguish it from the original determined version.

PROBLEM FORMULATION
We consider a situation where J source signals are observed by I microphones. Let sj(f, n) and xi(f, n) be the Short-Time Fourier Transform (STFT) coefficient of the j-th source signal and the i-th observed signal, where f and n are the frequency and time indices, respectively. We denote the vectors containing s1(f, n), · · · , sJ (f, n) and x1(f, n), · · · , xI (f, n) bys(f, n) = [s1(f, n), · · · , sJ (f, n)] T ∈ C J ,(1)x(f, n) = [x1(f, n), · · · , xI (f, n)] T ∈ C I ,(2)where (·) T denotes transpose. Now, we use a mixing system of the formx(f, n) = A(f )s(f, n),(3)A(f ) = [a1(f ), · · · , aJ (f )] ∈ C I×J ,(4)to describe the relationship between s(f, n) and x(f, n) where A(f ) is called the mixing matrix.Here, we assume that sj(f, n) independently follows a zeromean complex Gaussian distribution with variance vj (f,n) = E |sj (f, n)| 2 sj(f, n) ∼ N C (sj(f, n)|0, vj (f, n)).(5)Eq. (5) is called the Local Gaussian Model (LGM). When sj (f, n) and s j ′ (f, n) are independent for j = j ′ , s(f, n) followss(f, n) ∼ N C (s(f, n)|0, V(f, n)),(6)where V(f, n) is a diagonal matrix with diagonal entries v1(f, n), · · · , vJ (f, n). From Eq. (3) and Eq. (6), x(f, n) is shown to followx(f, n) ∼ N C (x(f, n)|0, A(f )V(f, n)A H (f )),(7)where (·) H denotes conjugate transpose. Thus, the log-likelihood of the mixing matrices A = {A(f )} f and the variances of source signals V = {vj (f, n)} f,n given the observed mixture signals X = {x(f, n)} f,n is given bylog p(X |A, V) c = − f,n tr(x H (f, n)(A(f )V(f, n)A H (f )) −1 x(f, n)) +logdet(A(f )V(f, n)A H (f )) ,(8)where c = denotes equality up to constant terms. If there is no constraint imposed on vj (f, n), Eq. (8) will be split into frequency-wise source separation problems. This indicates that there is a permutation ambiguity in the separated components for each frequency since permutation of j does not affect the value of the log-likelihood. Thus, we usually need to perform permutation alignment after A is obtained.

RELATED WORK


MNMF
The spatial covariance of the observed mixture signal A(f )V(f, n)A H (f, n) can be rewritten as the linear sum of the outer products of aj (f ) multiplied by vj (f, n):A(f )V(f, n)A H (f ) = j aj(f )vj (f, n)a H j (f ) = j vj (f, n)Rj (f ),(9)where Rj (f ) represents the spatial covariance of source j. As with IVA, MNMF makes it possible to jointly solve frequency-wise source separation and permutation alignment by imposing a constraint on vj (f, n). Specifically, vj (f, n) is modeled as the linear sum of Kj spectral templates hj,1(f ), · · · , hj,K j (f ) ≥ 0 scaled by time-varying activations uj,1(n), · · · , uj,K j (n) ≥ 0:vj (f, n) = K j k=1 h j,k (f )u j,k (n).(10)It is also possible to allow all the spectral templates to be shared by every source and let the contribution of the k-th spectral template to source j be determined in a data-driven manner. Thus, vj (f, n) can also be expressed asvj (f, n) = K k=1 b j,k h k (f )u k (n),(11)where b j,k ∈ [0, 1] is a continuous indicator variable that satisfies k b j,k = 1.Here, b j,k can be interpreted as the expectation of a binary indicator variable that describes the index of the source to which the k-th template is assigned.The optimization algorithm of MNMF consists of iteratively updating the spatial covariance matrices R = {Rj (f )} j,f , and the source modelsH1 = {h j,k (f )} j,k,f , U1 = {u j,k (n)} j,k,n or B = {b j,k } j,k , H2 = {h k (f )} k,f , U2 = {u k (n)} k,n .We can derive update equations using the principle of the Majorization-Minimization (MM) algorithm. For the update of R, we can use the solution to Algebraic Ricatti equationRj (f )Ψj(f )Rj (f ) = Ωj (f ),(12)whereΨj(f ) = n vj(f, n)X −1 (f, n),(13)Ωj(f ) = Rj(f ) n vj (f, n)X −1 (f, n)X(f, n)X −1 (f, n) Rj (f ). (14)Note that we have used X(f, n) andX(f, n) to representX(f, n) = x(f, n)x H (f, n),(15)X(f, n) = Aj(f )V(f, n)Aj (f ).(16)Performing (12) is empirically shown to help avoid computational instability. As in  #b4 , update rules for H1 and U1 can be derived asRj (f ) ← Rj (f ) + R H j (f ) / 2 and Rj (f ) ← Rj (f ) + ǫI after solving Eq.h j,k (f ) ← h j,k (f ) × n u j,k (n)tr(X −1 (f, n)X(f, n)X −1 (f, n)Rj (f )) n u j,k (n)tr(X −1 (f, n)Rj (f )) , (17) u j,k (n) ← u j,k (n) × f h j,k (f )tr(X −1 (f, n)X(f, n)X −1 (f, n)Rj (f )) f h j,k (f )tr(X −1 (f, n)Rj (f )) . (18)When vj (f, n) is given in the form of Eq. (11), update rules for B, H2, and U2 can be derived asb j,k ← b j,k × f,n h k (f )u k (n)tr(X −1 (f, n)X(f, n)X −1 (f, n)Rj (f )) f,n h k (f )u k (n)tr(X −1 (f, n)Rj (f )) , (19) h k (f ) ← h k (f ) × j,n b j,k u k (n)tr(X −1 (f, n)X(f, n)X −1 (f, n)Rj (f )) j,n b j,k u k (n)tr(X −1 (f, n)Rj (f )) ,(20)u k (n) ← u k (n) × j,f b j,k h k (f )tr(X −1 (f, n)X(f, n)X −1 (f, n)Rj (f )) j,f b j,k h k (f )tr(X −1 (f, n)Rj (f )) .(21)To ensure that B satisfies the sum-to-one constraint, we normalize B after performing Eq. (19) by b j,k ← b j,k / k b j,k and rescale H2 and U2 accordingly.

ILRMA
ILRMA is a special class of MNMF designed to solve determined source separation problems. Unlike MNMF, which uses the mixing system (Eq. (3)), ILRMA uses a separation system of the forms(f, n) = W H (f )x(f, n),(22)W(f ) = [w1(f ), · · · , wI (f )] ∈ C I×J ,(23)assuming the mixing matrix is invertible. The inverse matrix W H (f ) is called the separation matrix. From Eq. (6) and Eq. (22), x(f, n) is shown to followx(f, n) ∼ N C (x(f, n)|0, (W H (f )) −1 V(f, n)(W(f )) −1 ). (24)The log-likelihood of the separation matrices W = {W(f )} f and V given the observed signals X is given bylog p(X |W, V) c = 2N f log |detW H (f )| − f,n,j log vj (f, n) + |w H j (f )x(f, n)| 2 vj (f, n) ,(25)where vj (f, n) is modeled as Eq. (10) or Eq. (11) as with MNMF.As with MNMF, we can derive MM-based update equations for H1, U1 or B, H2, U2. Since ILRMA is a natural extension of IVA, we can use a fast update rule called the Iterative Projection (IP)  #b11  for the separation matrices, originally developed for IVA.

DNN Approach
There has been some studies attempting to integrate deep neural networks (DNNs) with the LGM-based multichannel source separation framework  #b12 .  #b12  proposes an algorithm that consists of updating vj(f, n) for each j via the forward computation of a pretrained DNN. Here, each DNN is trained so that it produces a denoised version of the input spectra. Hence, vj (f, n) is forced to get close to the spectra of clean speech at each iteration. However, updating vj (f, n) in this way does not guarantee an increase in the log-likelihood, which does not ensure the convergence of the devised algorithm.

MVAE
One limitation of the MNMF framework including ILRMA is that since vj (f, n) is restricted to Eq. (10), it can fail to work for sources with spectrograms that do not actually follow this form. The MVAE method is an extension of ILRMA that replaces Eq. (10) with a pretrained CVAE. LetS = {s(f, n)} f,n be the complex spectrogram of a particular sound source. MVAE models the generative model of S using a Conditional VAE (CVAE) with an auxiliary input c. Here, we assume that c is represented as a one-hot vector, indicating the class of a source. Thus, the elements of c must sum to unity. For example, if we consider speaker identities as the source class, each element of c will be associated with a different speaker.The CVAE consists of an encoder network and a decoder network, which are assumed to be trained using labeled training examples {Sm, cm} M m=1 prior to separation. The encoder distribution q φ (z|s, c) is expressed as a Gaussian distribution:q φ (z|S, c) = k N (z(k)|µ φ (k;S, σ 2 φ (k;S, c)),(26)where z denotes a latent space variable and z(k), µ φ (k;S), and σ 2 φ (k;S, c) represent the k-th elements of z, µ φ (S, c), and σ 2 φ (S, c), respectively. The decoder distribution p θ (S|z, c, g) is expressed as a zero-mean complex Gaussian distribution (LGM):p θ (S|z, c, g) = f,n N C (s(f, n)|0, v(f, n)),(27)v(f, n) = g · σ 2 θ (f, n; z, c),(28)where σ 2 θ (f, n; z, c) represents the (f, n)-th elements of the decoder output σ 2 θ (z, c) and g is the global scale of the generated spectrogram. Both the encoder and decoder network parameters φ, θ are trained using the following objective fucntion  J (φ, θ) = E (S,c)∼p D (S,c) E z∼q(z|S,c) [log p(S|z, c)] −KL[q(z|S, c)||p(z)] ,(29)

GENERALIZED MVAE
While the MVAE method is applicable only to determined mixtures, we propose generalizing it to so that it can also deal with underdetermined mixtures. As with the original MVAE method, we use the decoder network of the pretrained CVAE as the generative model of source power spectrograms. Fig. 1 shows an illustration of GMVAE and MNMF with the source model given by Eq.  #b9 .Since the decoder distribution is given in the same form as the LGM, we can use p θ (Sj |zj , cj , gj) to develop the log-likelihood of the form Eq.  #b7 . Hence, we can derive an iterative algorithm for estimating R, G = {gj} j , and Ψ = {zj , cj } j in the same way as the derivation of the MM-based algorithm for MNMF. According to  #b13 , we can show thatL = − log p(X |A, V) c ≤ j f,n tr(X(f, n)Pj (f, n)R −1 j (f, n)Pj (f, n)) vj (f, n) + vj (f, n)tr(K −1 (f, n)Rj (f, n)) ,(30)where the equality holds whenPj (f, n) = vj (f, n)Rj (f, n) j vj (f, n)Rj (f, n) −1 ,(31)K(f, n) = X(f, n).(32)Thus, we can use the right-hand side of this inequality as a majorizer of L where P = {Pj (f, n)} j,f,n and K = {K(f, n)} f,n are auxiliary variables. An iterative algorithm that consists of minimizing this majorizer with respect to R, G, and Ψ and updating P and K at Eq. (31) and Eq. (32) is guaranteed to converge to a stationary point of L. The optimal update of R is given as the solution to Eq.  #b11 . Since the majorizer is split into source-wise terms, Ψ can be updated parallelly using backpropagation. Note that we must take account of the sum-to-one constraints when updating cj . This can be easily implemented by inserting an appropriately designed softmax layer that outputs cj and treating dj as the parameter to be estimated instead. The optimal update of G is obtained ascj = softmax(dj),(33)¡ ¢ £ ¤ ¥ ¦ § ¨ © ! " # $gj ← gj × f,n σ 2 θ (f, n; zj , cj )tr(X −1 (f, n)X(f, n)X −1 (f, n)Rj (f )) f,n σ 2 θ (f, n; zj, cj )tr(X −1 (f, n)Rj (f )) .(34)The source separation algorithm of GMVAE is summarized as follows:1. Train φ and θ using Eq. (29).2. Initialize R, G, and Ψ = {zj , cj}.3. Iterate the following steps for each j: (c) Update gj using Eq. (34).

EXPERIMENTAL EVALUATIONS
The proposed method was evaluated on an underdetermined source separation task of separating out three sources from two microphone inputs. As the experimental data, we used speech samples of the Voice Conversion Challenge (VCC) 2018 dataset  #b14 , which contains recordings of six female and six male US English speakers. Specifically, we used a set of the utterances of two female and two male speakers, 'SF1', 'SF2', 'SM1', and 'SM2'. In this experiment, speaker identities are considered as the source class category: c is represented as a four-dimensional one-hot vector. 81 sentences and 35 sentences of each speaker were used for training and evaluation, respectively. Fig. 2 shows the position of microphones and sources.❞ and × show the microphones and sources, respectively. 10 speech mixtures are generated for four speaker patterns: SF1+SF2+SM2, SF1+SM1+SF2, SF1+SM1+SM2, and SM1+SF2+SM2. All the speech signals were resampled at 16 [kHz] and STFT analysis was conducted with 256 [ms] frame length and 128 [ms] hop length. We designed the encoder and decoder networks of the CVAE as a three-layer fully-convolutional network with gated linear units and a three-layer fully-deconvolutional network with gated linear units as in  #b9 . The Adam  #b15  (11) as baseline methods (MNMF1, MNMF2) for comparison. The separation algorithm was run for 300 iterations for the conventional methods and 100 iterations for the proposed. The parameters of the proposed method were initialized using the baseline method run for 200 iterations. Therefore, we tested the proposed method with two different initial settings (MVAE1, MVAE2). As the evaluation metrics, the Signal-to-Distortion Ratio (SDR), the source Image-to-Spatial distortion ratio (ISR), the Signal-to-Inference Ratio (SIR), and the Signal-to-Artifact Ratio (SAR)  #b16  between the reference signals and the separated signals were calculated for each mixture and averaged over 10 samples in each speaker pattern. Separation performance was investigated with two different reverberant conditions where the reverberation times T60 were set to 78 [ms] and 351 [ms], respectively. The separation performance under each reverberant condition is shown in Fig. 3 and 4. We can see that the proposed method obtained better separation performance than the baseline methods. The results imply that the use of VAE source model has successfully contributed to improving the separation performance.

CONCLUSION
This paper proposed the GMVAE method, which generalizes the MVAE method so that it can also be applied to multichannel source separation method under underdetermined conditions. Experimental results revealed that the GMVAE method achieved better performance than the baseline method.