Abstract
Object Classification is a key direction of research in signal and image processing, computer vision and artificial intelligence. The goal is to come up with algorithms that automatically analyze images and put them in predefined categories. This dissertation focuses on the theory and application of sparse signal processing and learning algorithms for image processing and computer vision, especially object classification problems. A key emphasis of this work is to formulate novel optimization problems for learning dictionary and structured sparse representations. Tractable solutions are proposed subsequently for the corresponding optimization problems. An important goal of this dissertation is to demonstrate the wide applications of these algorithmic tools for real-world applications. To that end, we explored important problems in the areas of: 1. Medical imaging: histopathological images acquired from mammalian tissues, human breast tissues, and human brain tissues. 2. Low-frequency (UHF to L-band) ultra-wideband (UWB) synthetic aperture radar: detecting bombs and mines buried under rough surfaces. 3. General object classification: face, flowers, objects, dogs, indoor scenes, etc. iv


Sparse signal processing has had remarkable recent success in problems such as classification, object detection, image and audio recognition, image super-resolution, etc. It essentially attempts to represent any signal (e.g. image, video, audio, etc.) using only a few number of observations or features from the same physical phenomenon. Based on this theory, a sparse representation-based classifier (SRC) [1] was initially developed for robust face recognition, and thereafter was extended to several other signal classification problems. It has been shown that SRC can be further improved by learning a dictionary from the training samples instead of using all of them as a dictionary. In the first part of the dissertation, we develop a discriminative dictionary learning framework for histopathological image analysis. Particularly, we propose an automatic feature discovery framework via learning class-specific dictionaries and present a lowcomplexity method for classification and disease grading in histopathology. Essentially, our Discriminative Feature-oriented Dictionary Learning (DFDL) [2] method learns classspecific dictionaries such that under a sparsity constraint, the learned dictionaries allow representing a new image sample parsimoniously via the dictionary corresponding to the class identity of the sample. At the same time, the dictionary is designed to be poorly capable of representing samples from other classes.iii The next part of this dissertation exploits the observation that although different objects possess distinct characteristics, they also usually share common patterns. A recently proposed dictionary learning framework has shown the benefit of separating the particularity and the commonality (COPAR) [3]. Inspired by this, we propose a novel method to explicitly and simultaneously learn a set of common patterns as well as classspecific features for classification with more intuitive constraints. Our dictionary learning framework is hence characterized by both a shared dictionary and particular (classspecific) dictionaries. The shared dictionary is constrained to have low-rank, i.e. its spanning subspace should have low dimension and the coefficients corresponding to this dictionary should be similar. For the particular dictionaries, we impose on them the wellknown constraints stated in the Fisher discrimination dictionary learning (FDDL) [4]. Further, new fast and accurate algorithms are developed to solve the subproblems in the learning step, accelerating its convergence. The said algorithms could also be applied to FDDL and its extensions. The efficiency of these algorithms is theoretically and experimentally verified by quantifying their complexity and running time with other well-known dictionary learning methods. The work has culminated into a dictionary learning toolbox called DICTOL [5] (https://github.com/tiepvupsu/DICTOL). The toolbox (in Matlab and Python) implements numerous sparse coding algorithms as well as widely used generative and discriminative dictionary learning methods. Many classical methods are sped up via new numerical optimization innovations.We also extend sparsity models to tensor sparsity models which significantly enhance classification accuracy for signals with multi-channels and multi-views. In this part, we present three novel sparsity-driven techniques, which not only exploit the subtle features of raw captured data but also take advantage of the polarization diversity and the aspect angle dependence information from multi-channel signals. First, the traditional SRC is generalized to exploit shared information of classes and various sparsity structures of tensor coefficients for multi-channel data. Corresponding tensor dictionary learning models are consequently proposed to enhance classification accuracy. Lastly, a new tensor sparsity model is proposed to model responses from multiple consecutive looks of objects, which is a unique characteristic of the dataset. 

Motivation
Object classification is one of the most important problems in machine intelligence systems. This is a well-studied problem in many important domains of data processing today. Typically, we are given images belonging to two or more classes, and the challenge is to develop an effective procedure of determining identity of a new sample. Application of object classification ranges broadly from spam email detection, fraud transaction detection to fingerprint verification, cancer detection, face identification, military vehicle recognition, self-driving cars, etc (see Fig. 1.1).In general, a classification system comprises of two main components: a feature extraction tool and a classifier. The feature extraction part plays a role in generating discriminative characteristics of each class. Traditional techniques in extracting features are hand-designed, such as Haar wavelets, Difference of Gaussians (DOG) filter, Gabor filters, histogram of oriented gradient (HOG) descriptors, SIFT descriptors [6], spatial pyramid matching [7] and many others. In some particular cases, the feature extraction also includes data dimension reduction step, which reduces the complexity of the classifier and hence, maximizes speed of the system. The classifier, which is often a result of a learning scheme, takes the extracted features as inputs and predicts identity of signals. Several classifier design techniques have been applied in practical applications, such as Naive Bayes  #b7 , Decision Trees  #b8 , Logistic Regression  #b9 , Neural Networks  #b10 , Support Vector Machines  #b11 , and Deep Learning  #b12  #b13  recently.One classifier can be seen as a function f that takes an input signal x (discrete or continuous) and generates an discrete output y ∈ C representing category/class of x. Based on several training pairs {(x 1 , y 1 ), (x 2 , y 2 ), . . . , (x N , y N )}, a classification algorithm tries to 'learn' the mapping f such that y n ≈ f (x n ) for as many as possible n ∈ {1, 2, . . . , N }. A good classifier is one that not only could well capture relationship . what it has seen, but also need to well represent new samples. This property, called generalization, is one of the most important factors in a classification system. However, attaining this property is usually a challenging task, as real-world classification problems exhibit difficulties. In particular, this dissertation emphasizes on addressing the following challenges:• Many practical problems encounter the issue of insufficient training. From probability perspective, the identity of a signal can be formulated as a maximum likelihood estimation problem, i.e. estimating p(y|x) for each possible category y ∈ C. Class decisions are made using empirical estimates of the true densities learned from available training data. Without prior knowledge of the (limited) training data, a system can severely misestimate the density, resulting in a poor classifier with lack of generalization property. This problem becomes more severe when data dimensionality increases. In this case, the volume of the space drastically increases. In order to achieve a stable system, the amount of data required to support the result often grows exponentially with the dimensionality. Unfortunately, this high-dimensional data phenomenon is commonly encountered in signal classification problems. For instance, a small gray image of size 200 × 200 has dimension of 40000. Particular images, such as hyperspectral or medical, have even more dimensions with million of pixels per channel and multiple channels per image. The problem persists even when low-dimensional image features are considered instead of entire images. Training insufficiency and high dimensionality are thus important concerns in signal classification.• Another challenge is that in practical problems, generous training is often not only limited but also taken under presence of noise or occlusion. This might be caused by limitations of devices, e.g. optical sensors, microscopes, or radar transmitter/receiver, that capture signals. Some unexpected sources of noise or distortions are often incorporated into the classification frameworks. In a face identification system, training faces might be captured under a good light conditions and/or well-aligned; a test face image, however, is usually captured under bad conditions with low light, occlusion by other objects, or at different angles. In a radar system, captured signals are commonly heavily interfered by other signals in the field.• Additionally, classification systems often face the problem of high within-class variance and small between-class variance. In a face identity problem, an image could include the face of the same individual wearing sunglasses, with hat, or at different angles. In a flower classification problem, a flower may be captured with different background, at different times of a day, or at different stages of the blooming process. This variability of samples from the same class is also called high within-class variance. Another challenge could happen in a classification problem is that different classes could share common patterns. Objects of different classes might be captured under the same background conditions. In histopathological images, an image in disease class could contain a large portion of healthy nuclei. This small between-class variance issue is another aspect we should consider.Sparse representations have emerged as a powerful tool for a range of signal processing applications. Applications include compressed sensing  #b14 , signal denoising, sparse signal recovery  #b15 , image inpainting  #b16 , image segmentation  #b17 , and more recently, signal classification. In such representations, most of signals can be expressed by a linear combination of few bases taken from a "dictionary". Based on this theory, a sparse representation-based classifier (SRC) [1] was initially developed for robust face recognition, and thereafter adapted to numerous signal/image classification problems, ranging from medical image classification [2, #b18  #b19 , hyperspectral image classification  #b20  #b21  #b22 , synthetic aperture radar (SAR) image classification  #b23 , recaptured image recognition  #b24 , video anomaly detection  #b25 , and several others  #b26  #b27  #b28  #b29  #b30  #b31 .The success of SRC-related methods firstly comes from the fact that sparsity models are often robust to noise and occlusions [1]. In addition, the insufficient training problem can be mitigated by incorporating prior knowledge of signals into the optimization problem during the inference process as regularization terms or sparsity constraints that capture signal relationships  #b19  #b26  #b32 . It has been shown that learning a dictionary from the training samples instead of using all of them as a dictionary can further enhance the performance of SRC.This dissertation proposes novel structured sparsity frameworks for different classification applications. These applications include but are not limited to disease diagnosis and cancer detection, ultra-wide band synthetic aperture radar signal classification, face identification, flower classification, and general object classification. The works in this dissertation have culminated into one software and two toolboxes which are widely used by peer researchers.The next section of this chapter provides overview of sparse representation-based classification and fundamental dictionary learning methods. The last section will present contributions and organization of this dissertation.

Sparse Representation-based Classification
A significant contribution to the development of algorithms for image classification that addressed some of aforementioned challenges up to some extent is a recent sparse representation-based classification (SRC) framework [1], which exploits the discriminative capability of sparse representation. Given a sufficiently diverse collection of training images from each class, any image from a specific class can be approximately represented as a linear combination of training images from the same class. Therefore, if we have training images of all classes and form a basis or dictionary based on that, any new and unseen test image has a sparse representation with respect to such overcomplete dictionary. It is worth to mention that sparsity assumption holds due to the class-specific design of dictionaries as well as the assumption of the linear representation model.Concretely, given a collection D ∈ R d×k i of objects from one class, in which each column of D is the vectorized version of one signal (image in this case), a new signal y ∈ R d from the same class can be approximately expressed as y ≈ Dx. In addition, this assumption is not true when D comprising images coming from other class. Now suppose that we have C classes of subject, and let D = [D 1 , D 2 , . . . , D C ] be the set of original training samples, where D i is the sub-set of training samples from class i. Denote by y a testing sample. The procedures of SRC are as follows:1. Sparsely code y on D via l 1 -norm minimization:x = arg min x { y − Dx + λ x 1 } (1.1)where λ is a scalar constant. where e i = y − D i δ i (x) and δ i (x) is the part ofx associated with class i.Although SRC scheme shows interesting results, the dictionary used in it may not be effective enough to represent the query images due to the uncertain and noisy information in the original training images. The coding complexity increases as more training data is involved in building the dictionary. In addition, using the original training samples as the dictionary could not fully exploit the discriminative information hidden in the training samples. On the other hand, using analytically designed off-the-shelf bases as dictionary (e.g.  #b33  uses Haar wavelets and Gabor wavelets as the dictionary) might be universal to all types of images but will not be effective enough for specific type of images such as face, digit and texture images. In fact, all the above mentioned problems of predefined dictionary can be addressed, at least to some extent, by learning properly a dictionary from the original training samples. The next subsections will review the Online Dictionary Learning Method for compact purpose and two well-known Discriminative Dictionary Learning methods used for classification purpose.

Online Dictionary Learning
When number of training images increases, concatenating all of them into one "fat" matrix D and then solving the sparse coding problem (4.8) would be a time-consuming task. Additionally, it would be extremely redundant if some images in one class look very similar. To address this problem, several dictionary learning methods have been proposed for the problem of reconstruction. Concretely, from the big training set Y of one class, the dictionary learning algorithm tries to find a comprehensive set of bases which have ability to sparsely represent all element in the set. This task could be done by solving the following optimization problem:(D * , X * ) = arg minD,X 1 N N i=1 y i − Dx i 2 2 + λ x i 1 (1.3)where columns of D are constrained by d j 2 2 ≤ 1 to avoid trivial solutions. Problem (1.3) could be rewritten in the matrix form:(D * , X * ) = arg min D,X Y − DX 2 F + λ X 1 (1.4)where X 1 is the sum of absolute values of all elements in X.Problem (1.4) is not simultaneously convex with respect to both D and X but convex with each variable if the other variable is fixed. The typical approach is as follows. First, suppose that D is fixed, then X could be found using LASSO  #b34 :X * = arg min X { Y − DX 2 F + λ X 1 } (1.5)Second, fixing X = X * and compute D by:D * = arg min D { Y − DX 2 F + λ X 1 } (1.6) = arg min D {trace(DFD T ) − 2trace(D T E)} (1.7)Mairal et al.  #b35  propose an algorithm for computing D by updating column by column until convergence:u j ← 1 F(j, j) (e − Df j ) + d j (1.8) d j ← 1 max( u j , 1) u j (1.9)where F(j, j) is the value of F at coordinate (j, j) and f j denotes the j-th column of F.The dictionary learned from this method has been shown to be comprehensive in terms of sparsely expressing in-class samples. Because ODL is trained using in-class samples only, it might or might not well present complementary samples. However, from classification view point, this fact could be useful in terms of discriminability. Several dictionary learning methods have been proposed for the classification purpose. Two well-known dictionary learning methods demonstrating impressive results in object recognition are LC-KSVD  #b36  and FDDL  #b37 , which are also reviewed in the following sections of this chapter.

Label Consistent K-SVD (LC-KSVD)
Z. Jiang et al.  #b36  propose another dictionary learning method which learns a single overcomplete dictionary and an optimal linear classifier simultaneously. It yields dictionaries so that feature points with the same class labels have similar sparse codes. Each dictionary item is chosen so that it can be associated with a particular label. It is claimed that the performance of the linear classifier depends on the discriminability of the input sparse codes x. For obtaining discriminative sparse codes x with the learned D, an objective function for dictionary construction is defined as:(D,X,Â) = arg min D,X,A Y − DX 2 F + α Q − AX 2 F (1.10)subject to:x i 0 ≤ L (1.11)where α controls the relative contribution between reconstruction and label consistent regularization, and Q = [q 1 , q 2 , . . . , q N ] ∈ R d×N are the 'discriminative' sparse codes of input signals Y for classification. They say thatq i = [q 1 i , q 2 i , . . . , q N i ] T = [0, . . . , 1, 1, . . . , 0] T ∈ R d is a 'discriminative'sparse code corresponding to an input signal y i , if the non-zero values of q i occur at those indicates where the input signal y i and the dictionary item d k share the same label.Classification scheme: After the desired dictionaryD has been learned, for a test image y, they first compute its sparse representation x by solving the optimization problem:x = arg minx y −Dx 2 2 subject to x 0 ≤ L (1.12)Then label of the image y is estimated by using the linear predictive classifierŴ:identity(y) = arg max j (l =Ŵx) (1.13)where l ∈ R m is the class label vector.

Fisher Discrimination Dictionary Learning (FDDL)
M. Yang et al.  #b37  proposed another dictionary learning method to improve the pattern classification performance compared to SRC [1]. A structured dictionary, whose bases have correspondence to the class labels, is learned so that the reconstruction error after sparse coding can be used for pattern classification. Meanwhile, the Fisher discrimination criterion is imposed on the coding coefficients so that they have small within-class scatter but big between-class scatter.Specifically, the "total" dictionary D consisting of c class-specific dictionaries D = [D 1 , D 2 , . . . , D c ] is learned via the following optimization problem:J D,X = arg min D,X c i=1 r(Y i , D, X i ) + λ 1 X 1 + λ 2 trace(S W (X) − S B (X)) + η X 2 F(1.14) where:• r(Y i , D, X i ) = Y i −DX i 2 F + Y i −D i X i i 2 F + c j=1,j =i D j X j i 2F : the discriminative fidelity term.• X j i : the coding coefficient of Y i over the sub-dictionary D j .• f (X) = trace(S W (X) − S B (X)) + η X 2 F : the discriminative coefficient term.More details about the optimization of FDDL and its classification scheme could be found at  #b37 . 

Dissertation Contributions and Organization
A snapshot of the main contributions of this dissertation is presented next. Publications related to the contribution in each chapter are also listed where applicable.In Chapter 2, the primary contribution is the proposal of a new Discriminative Feature-oriented Dictionary Learning (DFDL) method for automatic feature discovery in histopathological images. This proposal mitigates the generally difficulty of feature extraction in histopathological images. Our discriminative framework learns dictionaries that emphasize inter-class differences while keeping intra-class differences small, resulting in enhanced classification performance. The design is based on solving a sparsity constrained optimization problem, for which we develop a tractable algorithmic solution.Experimental validation of DFDL is carried out on three diverse histopathological datasets to show its broad applicability. The first dataset is courtesy of the Clarian Pathology Lab and Computer and Information Science Dept., Indiana University-Purdue University Indianapolis (IUPUI). The images acquired by the process described in  #b38  correspond to human Intraductal Breast Lesions (IBL). Two well-defined categories will be classified: Usual Ductal Hyperplasia (UDH)-benign, and Ductal Carcinoma In Situ (DCIS)-actionable. The second dataset contains images of brain cancer (glioblastoma or GBM) obtaind from The Cancer Genome Atlas (TCGA)  #b39  provided by the National Institute of Health, and will henceforth be referred as the TCGA dataset. For this dataset, we address the problem of detecting MicroVascular Proliferation (MVP) regions, which is an important indicator of a high grade glioma (HGG)  #b40 . The third dataset is provided by the Animal Diagnostics Lab (ADL), The Pennsylvania State University. It contains tissue images from three mammalian organs -kidney, lung and spleen. For each organ, images will be assigned into one of two categories-healthy or inflammatory. The samples of these three datasets are given in Figs Chapter 3 proposes a new low-rank shared dictionary learning framework (LRSDL) for automatically extracting both discriminative and shared bases in several widely used image datasets to enhance the classification performance of dictionary learning methods. Our framework simultaneously learns each class-dictionary per class to extract discriminative features and the shared features that all classes contain. For the shared part, we impose two intuitive constraints. First, the shared dictionary must have a low-rank structure. Otherwise, the shared dictionary may also expand to contain discriminative features. Second, we contend that the sparse coefficients corresponding to the shared dictionary should be almost similar. In other words, the contribution of the shared dictionary to reconstruct every signal should be close together. We will experimentally show that both of these constraints are crucial for the shared dictionary.Significantly, new accurate and efficient algorithms for selected existing and proposed dictionary learning methods are proposed. We present three effective algorithms for dictionary learning: i) sparse coefficient update in FDDL [4] by using FISTA  #b41 . We address the main challenge in this algorithm -how to calculate the gradient of a complicated function effectively -by introducing a new simple function M(•) on block matrices and a lemma to support the result. ii) Dictionary update in FDDL [4] by a simple ODL  #b35  procedure using M(•) and another lemma. Because it is an extension of FDDL, the proposed LRSDL also benefits from the aforementioned efficient procedures. iii) Dictionary update in DLSI  #b42  by a simple ADMM  #b43  procedure which requires only one matrix inversion instead of several matrix inversions as originally proposed in  #b42 . We subsequently show the proposed algorithms have both performance and computational benefits.We derive the computational complexity of numerous dictionary learning methods in terms of approximate number of operations (multiplications) needed. We also report complexities and experimental running time of aforementioned efficient algorithms and their original counterparts. Numerous sparse coding and dictionary learning algorithms in the manuscript are reproducible via a user-friendly toolbox. In Chapter 4, a framework for simultaneously denoising and classifying 2-D UWB SAR imagery is introduced. Subtle features from targets of interest are directly learned from their SAR imagery. The classification also exploits polarization diversity and consecutive aspect angle dependence information of targets. A generalized tensor discriminative dictionary learning (TensorDL) is also proposed when more training data involved. These dictionary learning frameworks are shown to be robust even with high levels of noise.Additionally, a relative SRC framework (ShiftSRC) is proposed to deal with multi-look data. Low-frequency UWB SAR signals are often captured at different views of objects, depending on the movement of the radar carriers. These signals contain uniquely important information of consecutive views. With ShiftSRC, this information will be comprehensively exploited. Importantly, a solution to the ShiftSRC framework can be obtained by an elegant modification on the training dictionary, resulting in a tensor sparse coding problem, which is similar to a problem proposed in the last paragraph. This work was done under the mentorship of Dr. Lam Nguyen at the U.S. Army Research Laboratory, Adelphi, MD. All tensor sparsity algorithms in this chapter are reproducible via a user-friendly toolbox. The toolbox written in Matlab is provided 4 with the hope of usage in future research via peer researchers.The material in this chapter was presented at the 2017 IEEE Radar Conference and is under review at the IEEE Transactions on Aerospace and Electronic Systems. On a related note, we employed a deep learning framework for simultaneously denoising and classifying UWB SAR imagery. This work is however not included in this dissertation. This work was recently presented as an invited talk at the 2018 IEEE Radar Conference.In Chapter 5, the main contributions of this dissertation are summarized.As a side note, apart from building discriminative models for signal classification, our research also solves other long-standing open problems in sparse signal and image processing. Using sparsity as a prior is tremendously interesting in a wide variety of applications; however, existing solutions to address this issue are sub-optimal and often fail to capture the intrinsic sparse structure of physical phenomenon. We have been trying to address a very fundamental question in this area of how to efficiently and effectively capture sparsity in natural signals by using the Spike and Slab priors. These priors have been of much recent interest in signal processing as a means of inducing sparsity in Bayesian inference. It is well-known that solving for the sparse coefficient vector to maximize these priors results in a hard non-convex and mixed integer programming problem. Most existing solutions to this optimization problem either involve simplifying assumptions/relaxations or are computationally expensive. We propose a new greedy and adaptive matching pursuit (AMP) algorithm to directly solve this hard problem. Essentially, in each step of the algorithm, the set of active elements would be updated by either adding or removing one index, whichever results in better improvement. In addition, the intermediate steps of the algorithm are calculated via an inexpensive Cholesky decomposition which makes the algorithm much faster. Results on simulated data sets as well as real-world image recovery challenges confirm the benefits of the proposed AMP, particularly in providing a superior cost-quality trade-off over existing alternatives. These findings recently appeared in 2017 at the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), and was nominated as a Finalist for the Best Student Paper Award. This work is nevertheless not included in this dissertation.Discriminative Feature-oriented Dictionary Learning for Histopathological Image Classification

Introduction
Over the past two decades, the U.S. Army has been investigating the capability of low-frequency, ultra-wideband (UWB) synthetic aperture radar (SAR) systems for the detection of buried and obscured targets in various applications, such as foliage penetration  #b85 , ground penetration  #b86 , and sensing-through-the-wall  #b87 . These systems must operate in the low-frequency spectrum spanning from UHF frequency band to L band to achieve both resolution and penetration capability. Although a lot of progress has been made over the years, one critical challenge that low-frequency UWB SAR technology still faces is discrimination of targets of interest from other natural and manmade clutter objects in the scene. The key issue is that that the targets of interest are typically small compared to the wavelength of the radar signals in this frequency band and have very low radar cross sections (RCSs). Thus, it is very difficult to discriminate targets and clutter objects using low-resolution SAR imagery.  SAR image pixel from the imaging area as follows:

Challenges and Motivation
While histopathological analysis shares some traits with other image classification problems, there are also principally distinct challenges specific to histopathology. The central challenge comes from the geometric richness of tissue images, resulting in the difficulty of obtaining reliable discriminative features for classification. Tissues from different organs have structural and morphological diversity which often leads to highly customized feature extraction solutions for each problem and hence the techniques lack broad applicability.Being mindful of the aforementioned challenges, we design via optimization, a discriminative dictionary for each class by imposing sparsity constraints that minimizes intra-class differences, while simultaneously emphasizing inter-class differences. On one hand, small intra-class differences encourage the comprehensibility of the set of learned bases, which has ability of representing in-class samples with only few bases (intra class sparsity). This encouragement forces the model to find the representative bases in that class. On the other hand, large inter-class differences prevent bases of a class from sparsely representing samples from other classes. Concretely, given a dictionary from a particular class D with k bases and a certain sparsity level L k, we define an Lsubspace of D as a span of a subset of L bases from D. Our proposed Discriminative Feature-oriented Dictionary Learning (DFDL) aims to build dictionaries with this key property: any sample from a class is reasonably close to an L-subspace of the associated dictionary while a complementary sample is far from any L-subspace of that dictionary. V L,ε (D) = {y : min Illustration of the proposed idea is shown in Fig. 2.1.x 0 ≤L y − Dx 2 2 ≤ ε} • in-class samples (Y); • complementary samples (Ȳ) V L,ε1 (D in-class ) V L,ε1 (D DFDL ) (D in-class , X * ) = = arg min D,X { Y −DX 2 F +λ X 1 } Goal: min x 0 ≤L y − Dx 2 2 ≤ ε 2 ε 2 ≤ min x 0 ≤L ȳ − Dx||

Contributions
The main contributions of this chapter are as follows:1. A framework for simultaneously denoising and classifying 2-D UWB SAR imagery 1 . Subtle features from targets of interest are directly learned from their SAR imagery. The classification also exploits polarization diversity and consecutive aspect angle dependence information of targets.

Notation
The vectorization of a small block (or patch) 1 extracted from an image is denoted as a column vector y ∈ R d which will be referred as a sample. In a classification problem where we have c different categories, collection of all data samples from class i (i can vary between 1 to c) forms the matrix X i ∈ R d×N i and let X i ∈ R d×N i be the matrix containing all complementary data samples i.e. those that are not in class i. We denote by D i ∈ R d×k i the dictionary of class i that is desired to be learned through our DFDL method.For a vector x ∈ R k , we denote by x 0 the number of its non-zero elements. The sparsity constraint of x can be formulated as x 0 ≤ L. For a matrix X , X 0 ≤ L means that each column of X has no more than L non-zero elements.

Discriminative Feature-oriented Dictionary Learning
We aim to build class-specific dictionaries D i such that each D i can sparsely represent samples from class i but is poorly capable of representing its complementary samples with small number of bases. Concretely, for the learned dictionaries we need: where L i controls the sparsity level. These two sets of conditions could be simplified in the matrix form:min x l 0 ≤L i y l − D i x lintra-class differences:1 N i min X i 0 ≤L i Y i − D i X i 2 F small, (2.1)inter-class differences:1 N i min Y i 0 ≤L i X i − D i X i 2 F large. (2.2)The averaging operations 1 N i and 1 N i are taken here for avoiding the case where the largeness of inter-class differences is solely resulting fromN i N i .For simplicity, from now on, we consider only one class and drop the class index in each notion, i.e., using Y, D, X, X, N,N , L instead of Y i , D i , X i , X i , N i ,N i and L i . Based on the argument above, we formulate the optimization problem for each dictionary:D * = arg min D 1 N min X 0 ≤L Y − DX 2 F − ρ N min X 0 ≤L Y − DX 2 F , (2.3)where ρ is a positive regularization parameter. The first term in the above optimization problem encourages intra-class differences to be small, while the second term, with minus sign, emphasizes inter-class differences. By solving the above problem, we can jointly find the appropriate dictionaries as we desire in (2.1) and (2.2).How to choose L: The sparsity level L for classes might be different. For one class, if L is too small, the dictionary might not appropriately express in-class samples, while if it is too large, the dictionary might be able to represent complementary samples as well. In both cases, the classifier might fail to determine identity of one new test sample. We propose a method for estimating L as follows. First, a dictionary is learned using ODL  #b35  using in-class samples Y only:(D 0 , X 0 ) = arg min D,X { Y − DX 2 F + λ X 1 },(2.4)where λ is a positive regularization parameter controlling the sparsity level. Note that the same λ can still lead to different L for different classes, depending on the intra-class variablity of each class. Without prior knowledge of those variablities, we choose the same λ for every class. After D 0 and X 0 have been computed, D 0 could be utilized as a warm initialization of D in our algorithm, X 0 could be used to estimate the sparsity level L:L ≈ 1 N N i=1 x 0 i 0 . (2.5)Classification scheme: In the same manner with SRC [1], a new patch y is classified as follows. Firstly, the sparse codesx are calculated via l 1 -norm minimization:x = arg min x y − D total x 2 2 + γ x 1 ,(2.6)where D total = [D 1 , D 2 , . . . , D c ] is the collection of all dictionaries and γ is a scalar constant. Secondly, the identity of y is determined as: arg min i∈{1,...,c}{r i (y)} where r i (y) = y − D i δ i (x) 2 (2.7)and δ i (x) is part ofx associated with class i.

Proposed solution
We use an iterative method to find the optimal solution for the problem in (2.3). Specifically, the process is iterative by fixing D while optimizing X and X and vice versa.In the sparse coding step, with fixed D, optimal sparse codes X * , X * can be found by solving:X * = arg min X 0 ≤L Y − DX 2 F ; X * = arg min X 0 ≤L Y − DX 2 F .With the same dictionary D, these two sparse coding problems can be combined into the following one:X * = arg minX 0 ≤L Ŷ − DX 2 F . (2.8) withŶ = [Y, Y]being the matrix of all training samples andX = [X, X]. This sparse coding problem can be solved effectively by OMP  #b65  using SPAMS toolbox  #b66 .For the bases update stage, D * is found by solving: We have used the equation M 2 F = trace(MM T ) for any matrix M to derive (2.10) from (2.9) and denoted:D * = arg min D 1 N Y − DX 2 F − ρ N Y − DX 2 F ,(2.E = 1 N YX T − ρ NXX T ; F = 1 N XX T − ρ NXX T . (2.11)The objective function in (2.10) is very similar to the objective function in the dictionary update stage problem in  #b35  except that it is not guaranteed to be convex. It is convex if and only if F is positive semidefinite. For the discriminative dictionary learning problem, the symmetric matrix F is not guaranteed to be positive semidefinite, even all of its eigenvalues are real. In the worst case, where F is negative semidefinite, the objective function in (2.10) becomes concave; if we apply the same dictionary update algorithm as in  #b35 , we will obtain its maximum solution instead of the minimum.To deal with this situation, we propose a technique which convexifies the objective function based on the following observation.If we look back to the main optimization problem stated in (2.3):D * = arg min D 1 N min X 0 ≤L Y − DX 2 F − ρ N min X 0 ≤L Y − DX 2 F , we can see that if D = d 1 d 2 . . . d k is an optimal solution, then D = d 1 a 1 d 2 a 2 . . . d k a kis also an optimal solution as we multiply j-th rows of optimal X and X by a j , where a j , j = 1, 2, . . . , k, are arbitrary nonzero scalars. Consequently, we can introduce constraints: d i 2 2 = 1, j = 1, 2, . . . , k, without affecting optimal value of (2.10). With these constraints, trace(Dλ min (F)I k D T ) = λ min (F)trace(D T D) = λ min (F) k i=1 d T i d i = kλ min (F),where λ min (F) is the minimum eigenvalue of F and I k denotes the identity matrix, is a constant. Substracting this constant from the objective function will not change the optimal solution to (2.10).Essentially, the following problem in (2.12) is equivalent to (2.10):D * = arg min D {−2trace(ED T ) + trace D(F − λ min (F)I k )D T } (2.12)subject to: d i 2 2 = 1, i = 1, 2, . . . , k. The matrixF = F − λ min (F)I k is guaranteed to be positive semidefinite since all of its eignenvalues now are nonnegative, and hence the objective function in (2.12) is convex. Now, this optimization problem is very similar to the dictionary update problem in  #b35 . Then, D * could be updated by the following iterations until convergence:u j ← 1 F j,j (e j − Df j ) + d j . (2.13) d j ← u j u j 2 .(2.14) while not converged do 2. Fix D = D * and update X, X by solving (2.8); 3. Fix X, X, calculate:E = 1 N YX T − ρ NXX T ; F = 1 N XX T − ρ NXX T .4. Update D from:D * = arg min D − 2trace(ED T ) + trace D F − λ min (F)I D Tsubject to: d i 2 2 = 1, i = 1, 2, . . . , k. end while RETURN: D * end function whereF j,j is the value ofF at coordinate (j, j) andf j denotes the j-th column ofF.Our DFDL algorithm is summarized in Algorithm 1.

Overall classification procedures for three datasets
In this section, we propose a DFDL-based procedure for classifying images in three datasets.

IBL and ADL datasets
The key idea in this procedure is that a healthy tissue image largely consists of healthy patches which cover a dominant portion of the tissue. This procedure is shown in Fig.  2.2 and consists of the following three steps:Step 1: Training DFDL bases for each class. From labeled training images, training patches are randomly extracted (they might be overlapping). The size of these patches is picked based on pathologist input and/or chosen by cross validation  #b67 . After we have a set of healthy patches and a set of diseased patches for training, class-specific DFDL dictionaries and the associated classifier are trained by using Algorithm 1.  Step 2: Learning a threshold θ for proportion of healthy patches in one healthy image. Labeled training images are now divided into non-overlapping patches. Each of these patches is then classified using the DFDL classifier as described in Eq. (2.6) and (2.7). The main purpose of this step is to find the threshold θ such that healthy images have proportion of healthy patches greater or equal to θ and diseased ones have proportion of diseased patches less than θ. We can consider the proportion of healthy patches in one training image as its one-dimension feature. This feature is then put into a simple SVM to learn the threshold θ.Step 3: Classifying test images. For an unseen test image, we calculate the proportion τ of healthy patches in the same way described in Step 2. Now, the identity of the image is determined by comparing the proportion τ to θ. It is categorized as healthy (diseased) if τ ≥ (<)θ. The procedure readily generalizes to multi-class problems.

MVP detection problem in TCGA dataset
As described earlier, MicroVascular Proliferation (MVP) is the presence of blood vessels in a tissue and it is an important indicator of a high-grade tumor in brain glioma. Essentially presence of one such region in the tissue image indicates the high-grade tumor. Detection of such regions in TCGA dataset is an inherently hard problem and unlike classifying images in IBL and ADL datasets which are distinguishable by researching small regions, it requires more effort and investigation on larger connected regions. This is due to the fact that an MVP region may significantly vary in size and is usually surrounded by tumor cells which are actually benign or low grade. In addition, an MVP  Step 2: MVP detection phase: A new unknown image is decomposed into nonoverlapping patches. These patches are then classified using DFDL model learned before. After this step, we have a collection of patches classified as MVP. A region with large number of connected classified-as-MVP patches could be considered as an MVP region. If the final image does not contain any MVP region, we categorize the image as a Not MVP; otherwise, it is classified as MVP. The definition of connected regions contains a parameter m, which is the number of connected patches. Depending on m, positive patches might or might not appear in the final step. Specifically, if m is small, false positives tend to be determined as MVP patches; if m is large, true positives are highly likely eliminated. To determine m, we vary it from 1 to 20 and compute its ROC curve for training images and then simply pick the point which is closest to the origin and find the optimal m. This procedure is visualized in Fig. 2.3.

Validation and Experimental Results
In this section, we present the experimental results of applying DFDL to three diverse histopathological image datasets and compare our results with different competing methods:• WND-CHARM  #b51  #b52  in conjunction with SVM: this method combines state-of-theart feature extraction and classification methods. We use the collection of features from WND-CHARM, which is known to be a powerful toolkit of features for medical images. While the original paper used weighted nearest neighbor as a classifier, we use a more powerful classifier (SVM  #b68 ) to further enhance classification accuracy. We pick the most relevant features for histopathology  #b45 , including but not limited to (color channel-wise) histogram information, image statistics, morphological features and wavelet coefficients from each color channel. The source code for WND-CHARM is made available by the National Institute of Health online at http://ome.grc.nia.nih.gov/.• SRC [1]: We apply SRC on the vectorization of the luminance channel of the histopathological images, as proposed initially for face recognition and applied widely thereafter.• SHIRC  #b19 : Srinivas et al.  #b19  #b46  presented a simultaneous sparsity model for multi-channel histopathology image representation and classification which extends the standard SRC [1] approach by designing three color dictionaries corresponding to the RGB channels. The MATLAB code for the algorithms is posted online at: http://signal.ee.psu.edu/histimg.html.• LC-KSVD  #b36  and FDDL  #b37 : These are two well-known dictionary learning methods which were applied to object recognition such as face, digit, gender, vehicle, animal, etc, but to our knowledge, have not been applied to histopathological image classification. To obtain a fair comparison, dictionaries are learned on the same training patches. Classification is then carried out using the learned dictionaries on non-overlapping patches in the same way described in Section 2.2.4.• Nayak's: In recent relevant work, Nayak et al.  #b47  proposed a patch-based method to solve the problem of classification of tumor histopathology via sparse feature learning. The feature vectors are then fed into SVM to find the class label of each patch. ADL dataset: This dataset contains bovine histopathology images from three subdatasets of kidney, lung and spleen. Each sub-dataset consists of images of size 4000 × 3000 pixels from two classes: healthy and inflammatory. Each class has around 150 images from which 40 images are chosen for training, the remaining ones are used for testing. Number of training patches, bases, λ and ρ are the same as in the IBL dataset. The classification procedure for IBL and ADL datasets is described in Section 2.2.4.1.

Experimental Set-Up: Image Datasets
TCGA dataset: We use a total of 190 images (RoIs) (resolution 3000 × 3000) from the TCGA, in which 57 images contain MVP regions and 133 ones have no traces of MVP. From each class, 20 images are randomly selected for training. The classification procedure for this dataset is described in Section 2.2.4.2.Each tissue specimen in these datasets is fixed on a scanning bed and digitized using a digitizer at 40× magnification.

Validation of Central Idea: Visualization of Discovered Features
This section provides experimental validation of the central hypothesis of this chapter: by imposing sparsity constraint on forcing intra-class differences to be small, while simultaneously emphasizing inter-class differences, the class-specific bases obtained are discriminative.Example bases obtained by different dictionary learning methods are visualized in Fig.  2.4. By visualizing these bases, we emphasize that our DFDL is able to look for discriminative visual features from which pathologists could understand the reasons behind diseases. In the spleen dataset for example, it is really difficult to realize the differences between two classes by human eyes. However, by looking at DFDL learned bases, we can see that the distribution of cells in two classes are different such that a larger number of cells appears in a normal patch. These differences may provide pathologists one visual cue to classify these images without advanced tools. Moreover, for IBL dataset, UDH bases visualize elongated cells with sharp edges while DCIS bases present more rounded cells with blurry boundaries, which is consistent with their descriptions in  #b19  and  #b38 ; for ADL-Lung, we observe that a healthy lung is characterized by large clear openings of the alveoli, while in the inflamed lung, the alveoli are filled with bluish-purple inflammatory cells. This distinction is very clear in the bases learned from DFDL where white regions appear more in normal bases than in inflammatory bases and no such information can be deduced from LC-KSVD or FDDL bases. In comparison, FDDL fails to discover discriminative visual features that are interpretable and LC-KSVD learns bases with the inter-class differences being less significant than DFDL bases. Furthermore, these LC-KSVD bases do not present key properties of each class, especially in lung dataset.To understand more about the significance of discriminative bases for classification, let us first go back to SRC [1]. For simplicity, let us consider a problem with two classes with corresponding dictionaries D 1 and D 2 . The identity of a new patch y, which, for instance, comes from class 1, is determined by equations (2.6) and (2.7). In order to obtain good results, we expect most of active coefficients to be present in δ 1 (x). For δ 2 (x), its non-zeros, if they exists should have small magnitude. Now, suppose that one basis, d 1 , in D 1 looks very similar to another basis, d 2 , in D 2 . When doing sparse coding, if one patch in class 1 uses d 1 for reconstruction, it is highly likely that a similar patch y in the same class uses d 2 for reconstruction instead. This misusage may lead to the case y − D 1 δ 1 (x) > y − D 2 δ 2 (x) , resulting in a misclassified patch. For this reason, the more discriminative bases are, the better the performance. To formally verify this argument, we do one experiment on one normal and one inflammatory image from lung dataset in which the differences of DFDL bases and LCKSVD bases are most significant. From these images, patches are extracted, then their sparse codes are calculated using two dictionaries formed by DFDL bases and LC-KSVD bases.   2.5f) are more uniformly distributed on both sides of the red line, which adversely affects classification. In Fig. 2.5e), although active coefficients are strongly concentrated to the left of the red line, this effect is even more pronounced with DFDL, i.e. in Fig. 2.5c).

Overall Classification Accuracy


Complexity analysis
We compare the computational complexity for the efficient algorithms and their corresponding original algorithms. We also evaluate the total complexity of the proposed LRSDL and competing dictionary learning methods: DLSI  #b42 , COPAR [3] and FDDL  #b37 . The complexity for each algorithm is estimated as the (approximate) number of multiplications required for one iteration (sparse code update and dictionary update). For simplicity, we assume: i) number of training samples, number of dictionary bases in each class (and the shared class) are the same, which means: n c = n, k i = k. ii) The number of bases in each dictionary is comparable to number of training samples per class and much less than the signal dimension, i.e. k ≈ n d. iii) Each iterative algorithm requires q iterations to convergence. For consistency, we have changed notations in those methods by denoting Y as training sample and X as the sparse code.In the following analysis, we use the fact that: i) if A ∈ R m×n , B ∈ R n×p , then the matrix multiplication AB has complexity mnp. ii) If A ∈ R n×n is nonsingular, then the matrix inversion A −1 has complexity n 3 . iii) The singular value decomposition of a matrix A ∈ R p×q , p > q, is assumed to have complexity O(pq 2 ).

Statistical Results: Confusion Matrices and ROC Curves
Next, we present a more elaborate interpretation of classification performance in the form of confusion matrices and ROC curves. Each row of a confusion matrix refers to the actual class identity of test images and each column indicates the classifier output. Typically in medical image classification problems, pathologists desire algorithms that reduce the probability of miss (diseased images are misclassified as healthy ones) while also ensuring that the false alarm rate remains low. However, there is a trade-off between these two quantities, conveniently described using receiver operating characteristic (ROC) curves. The lowest curve (closest to the origin) has the best overall performance and the optimal operating point minimizes the sum of the miss and false alarm probabilities. It is evident that ROC curves for DFDL perform best in comparison to those of other state-of-the-art methods. Remark: Note for ROC comparisons, we compare the different flavors of dictionary learning methods (the proposed DFDL, LC-KSVD, FDDL and Nayak's), this is because as Table 2.5 shows, they are the most competitive methods. Note for the IBL and ADL datasets, θ, as defined in Fig. 2.2, is changed from 0 to 1 to acquire the curves; whereas for the TCGA dataset, number of connected classified-as-MVP patches, m, is changed from 1 to 20 to obtain the curves. It is worth re-emphasizing that DFDL achieves these results even as its complexity is lower than competing methods.

Performance vs. size of training set
Real-world classification tasks often have to contend with lack of availability of large training sets. To understand training dependence of the various techniques, we present a comparison of overall classification accuracy as a function of the training set size of the different methods. In Figure 3.11, overall classification accuracies are reported for first five datasets 2 corresponding to various scenarios. It is readily apparent that LRSDL exhibits the most graceful decline as training is reduced. In addition, LRSDL also shows high performance even with low training on AR datasets. Figure 3.10 shows the performance of LRSDL on the AR face dataset with different values of λ 1 , λ 2 , and η with other parameters fixed. We first set these three parameters to 0.003 then vary each parameter from 10 −4 to 0.3 while two others are fixed. We observe that the performance is robust to different values with the accuracies being greater than 98% in most cases. It also shows that LRSDL achieves the best performance when λ 1 = 0.01, λ 2 = 0.003, η = 0.003.

Performance vs. number of training bases
We now compare the behavior of each dictionary learning method as the number of bases in each dictionary varies from 200 to 600 (with patch size being fixed at 20 × 20 pixels). Results reported in Fig. 2.10 confirm that DFDL again outperforms other methods. In general, overall accuracies of DFDL on different datasets remain high when we reduce number of training bases. Interpreted another way, these results illustrate that DFDL is fairly robust to changes in parameters, which is a highly desirable trait in practice.

Discussion and Conclusion
In this chapter, our primary contribution is the development of a discriminative dictionary learning framework via the introduction of a shared dictionary with two crucial constraints. First, the shared dictionary is constrained to be low-rank. Second, the sparse coefficients corresponding to the shared dictionary obey a similarity constraint. In conjunction with discriminative model as proposed in [4, #b37 , this leads to a more flexible model where shared features are excluded before doing classification. An important benefit of this model is the robustness of the framework to size (k 0 ) and the regularization parameter (η) of the shared dictionary. In comparison with state-of-the-art algorithms developed specifically for these tasks, our LRSDL approach offers better classification performance on average.In Section 3.2.4 and 3.2.5, we discuss the efficient algorithms for FDDL [4], DLSI  #b42 , then flexibly apply them into more sophisticated models. Thereafter in Section 3.3 and 3.4.2, we both theoretically and practically show that the proposed algorithms indeed significantly improve cost functions and run time speeds of different dictionary learning algorithms. The complexity analysis also shows that the proposed LRSDL requires less computation than competing models.As proposed, the LRSDL model learns a dictionary shared by every class. In some practical problems, a feature may belong to more than one but not all classes. Very recently, researchers have begun to address this issue  #b83  #b84 . In future work, we will investigate the design of hierarchical models for extracting common features among classes.Classifying Multi-channel UWB SAR Imagery via Tensor Sparsity Learning Techniques

Closely Related work and Motivation
The assumption made by most discriminative dictionary learning methods, i.e. nonoverlapping subspaces, is unrealistic in practice. Often objects from different classes share some common features, e.g. background in scene classification. This problem has been partially addressed by recent efforts, namely DLSI  #b42 , COPAR [3], JDL  #b32  and CSDL  #b69 . However, DLSI does not explicitly learn shared features since they are still hidden in the sub-dictionaries. COPAR, JDL and CSDL explicitly learn a shared dictionary D 0 but suffer from the following drawbacks. First, we contend that the subspace spanned by columns of the shared dictionary must have low rank. Otherwise, class-specific features may also get represented by the shared dictionary. InIdeally, different classes lie in non-overlappling subspaces. In this case, X is block diagonal.≈ [Y 1 . . . Y c . . . Y C ] Y [ D 1 . . . D c . . . D C ] D × X Figure 3.1: Ideal structure of the coefficient matrix in SRC.the worst case, the shared dictionary span may include all classes, greatly diminishing the classification ability. Second, the coefficients (in each column of the sparse coefficient matrix) corresponding to the shared dictionary should be similar. This implies that features are shared between training samples from different classes via the "shared dictionary". In this chapter, we develop a new low-rank shared dictionary learning framework (LRSDL) which satisfies the aforementioned properties. Our framework is basically a generalized version of the well-known FDDL [4, #b37  with the additional capability of capturing shared features, resulting in better performance. We also show practical merits of enforcing these constraints are significant.The typical strategy in optimizing general dictionary learning problems is to alternatively solve their subproblems where sparse coefficients X are found while fixing dictionary D or vice versa. In discriminative dictionary learning models, both X and D matrices furthermore comprise of several small class-specific blocks constrained by complicated structures, usually resulting in high computational complexity. Traditionally, X, and D are solved block-by-block until convergence. Particularly, each block X c (or D c in dictionary update ) is solved by again fixing all other blocksX i , i = c (or D i , i = c).Although this greedy process leads to a simple algorithm, it not only produces inaccurate solutions but also requires huge computation. In this chapter, we aim to mitigate these drawbacks by proposing efficient and accurate algorithms which allows to directly solve X and D in two fundamental discriminative dictionary learning methods: FDDL [4] and DLSI  #b42 . These algorithms can also be applied to speed-up our proposed LRSDL, COPAR [3], D 2 L 2 R 2  #b44  and other related works.

Discriminative dictionary learning framework 3.2.1 Notation
In addition to notation stated in the Introduction, let D 0 be the shared dictionary, I be the identity matrix with dimension inferred from context. For c = 1, . . . , C;i = 0, 1, . . . , C, suppose that Y c ∈ R d×nc and Y ∈ R d×N with N = C c=1 n c ; D i ∈ R d×k i ,In real problems, different classes share some common features (represented by D 0 ).We model the shared dictionary D 0 as a low-rank matrix. m 1 X 1 − M 1 2 F m c X c − M c 2 F m C X C − M C 2 F m 0 X 0 − M 0 2 F m Goal: X c −M c 2 F (intra class) small. M c − M 2 F (inter class) lagre. X 0 − M 0 2 F small. a) b) c)D ∈ R d×K with K = C c=1 k c ; and X ∈ R K×N . Denote by X i the sparse coefficient of Y on D i , by X c ∈ R K×Nc the sparse coefficient of Y c on D, by X i c the sparse coefficient of Y c on D i . Let D = D D 0 be the total dictionary, X = [X T , (X 0 ) T ] T and X c = [(X c ) T , (X 0 c ) T ] T .For every dictionary learning problem, we implicitly constrain each basis to have its Euclidean norm no greater than 1. These variables are visualized in Figure 3.2a).Let m, m 0 , and m c be the mean of X, X 0 , and X c columns, respectively. Given a matrix A and a natural number n, define µ(A, n) as a matrix with n same columns, each column being the mean vector of all columns of A. If n is ignored, we implicitly set n as the number of columns of A. Let M c = µ(X c ), M 0 = µ(X 0 ), and M = µ(X, n) be the mean matrices. The number of columns n depends on context, e.g. by writing M c − M, we mean that n = n c . The 'mean vectors' are illustrated in Figure 3.2c).Given a function f (A, B) with A and B being two sets of variables, define f A (B) = f (A, B) as a function of B when the set of variables A is fixed. Greek letters (λ, λ 1 , λ 2 , η) represent positive regularization parameters. Given a block matrix A, define a function M(A) as follows:    A 11 . . . A 1C A 21 . . . A 2C . . . . . . . . . A C1 . . . A CC     A → A +     A 11 . . . 0 0 . . . 0 . . . . . . . . . 0 . . . A CC     M(A).(3.1)That is, M(A) doubles diagonal blocks of A. The row and column partitions of A are inferred from context. M(A) is a computationally inexpensive function of A and will be widely used in our LRSDL algorithm and the toolbox.We also recall here the FISTA algorithm  #b41  for solving the family of problems:X = arg min X h(X) + λ X 1 ,(3.2)where h(X) is convex, continuously differentiable with Lipschitz continuous gradient. FISTA is an iterative method which requires to calculate gradient of h(X) at each iteration. In this chapter, we will focus on calculating the gradient of h.

Closely related work: Fisher discrimination dictionary learning (FDDL)
FDDL  #b37  has been used broadly as a technique for exploiting both structured dictionary and learning discriminative coefficient. Specifically, the discriminative dictionary D and the sparse coefficient matrix X are learned based on minimizing the following cost function:J Y (D, X) = 1 2 f Y (D, X) + λ 1 X 1 + λ 2 2 g(X), (3.3) where f Y (D, X) = C c=1r Yc (D, X c ) is the discriminative fidelity with:r Yc (D, X c ) = Y c − DX c 2 F + Y c − D c X c c 2 F + j =c D j X j c 2 F , g(X) = C c=1 ( X c − M c 2 F − M c − M 2 F ) + X 2 Fis the Fisher-based discriminative coefficient term, and the l 1 -norm encouraging the sparsity of coefficients. The last term in r Yc (D, X c ) means that D j has a small contribution to the representation of Y c for all j = c. With the last term X 2 F in g(X), the cost function becomes convex with respect to X.  X 0 1 X 0 c X 0 C X 0 Without small X 0 − M 0 2 F X 0 1 X 0 c X 0 C With small X 0 − M 0 2

Proposed Low-rank shared dictionary learning (LRSDL)
The shared dictionary needs to satisfy the following properties: 1) Generativity: As the common part, the most important property of the shared dictionary is to represent samples from all classes [3, #b32  #b69 . In other words, it is expected that Y c can be well represented by the collaboration of the particular dictionary D c and the shared dictionary D 0 . Concretely, the discriminative fidelity term f Y (D, X) in (3.3) can be extended to f Y (D, X) = C c=1 r Yc (D, X c ) with r Yc (D, X c ) being defined as: Figure 3.2b)), we have:Y c − DX c 2 F + Y c − D c X c c − D 0 X 0 c 2 F + C j=1,j =c D j X j c 2 F . Note that sincer Yc (D, X c ) = rȲ c (D, X c ) with Y c = Y c − D 0 X 0 c (seef Y (D, X) = fȲ(D, X), with Y = Y − D 0 X 0 .This generativity property can also be seen in Figure 3.3a). In this figure, the intersection of different subspaces, each representing one class, is one subspace visualized by the light brown region. One class subspace, for instance class 1, can be well represented by the ideal shared atoms (dark brown triangles) and the corresponding class-specific atoms (red squares).2) Low-rankness: The stated generativity property is only the necessary condition for a set of atoms to qualify a shared dictionary. Note that the set of atoms inside the shaded ellipse in Figure 3.3a) also satisfies the generativity property: along with the remaining red squares, these atoms well represent class 1 subspace; same can be observed for class 2. In the worst case, the set including all the atoms can also satisfy the generativity property, and in that undesirable case, there would be no discriminative features remaining in the class-specific dictionaries. Low-rankness is hence necessary to prevent the shared dictionary from absorbing discriminative atoms. The constraint is natural based on the observation that the subspace spanned by the shared dictionary has low dimension. Concretely, we use the nuclear norm regularization D 0 * , which is the convex relaxation of rank(D 0 )  #b70 , to force the shared dictionary to be low-rank.In contrast with our work, existing approaches that employ shared dictionaries, i.e. COPAR [3] and JDL  #b32 , do not incorporate this crucial constraint.3) Code similarity: In the classification step, a test sample y is decomposed into two parts: the part represented by the shared dictionary D 0 x 0 and the part expressed by the remaining dictionary Dx. Because D 0 x 0 is not expected to contain class-specific features, it can be excluded before doing classification. The shared code x 0 can be considered as the contribution of the shared dictionary to the representation of y. Even if the shared dictionary already has low-rank, its contributions to each class might be different as illustrated in Figure 3.3b), the top row. In this case, the different contributions measured by X 0 convey class-specific features, which we aim to avoid. Naturally, the regularization term X 0 − M 0 is added to our proposed objective function to force each x 0 to be close to the mean vector m 0 of all X 0 . With this constraint, the Fisher-based discriminative coefficient term g(X) is extended to g(X) defined as:g(X) = g(X) + X 0 − M 0 2 F ,(3.4)Altogether, the cost function J Y (D, X) of our proposed LRSDL is:J Y (D, X) = 1 2 f Y (D, X) + λ 1 X 1 + λ 2 2 g(X) + η D 0 * . (3.5)By minimizing this objective function, we can jointly find the class specific and shared dictionaries. Notice that if there is no shared dictionary D 0 (by setting k 0 = 0), then D, X become D, X, respectively, J Y (D, X) becomes J Y (D, X) and LRSDL reduces to FDDL.

Classification scheme:
After the learning process, we obtain the total dictionary D and mean vectors m c , m 0 . For a new test sample y, first we find its coefficient vector x = [x T , (x 0 ) T ] T with the sparsity constraint on x and further encourage x 0 to be close to m 0 :x = arg min x 1 2 y − Dx 2 2 + λ 2 2 x 0 − m 0 2 2 + λ 1 x 1 . (3.6)Using x as calculated above, we extract the contribution of the shared dictionary to obtain y = y − D 0 x 0 . The identity of y is determined by:arg min 1≤c≤C (w y − D c x c 2 2 + (1 − w) x − m c 2 2 ),(3.7)where w ∈ [0, 1] is a preset weight for balancing the contribution of the two terms.

Efficient solutions for optimization problems
Before diving into minimizing the LRSDL objective function in (3.5), we first present efficient algorithms for minimizing the FDDL objective function in (3.3).

Efficient FDDL dictionary update
Recall that in  #b37 , the dictionary update step is divided into C subproblems, each updates one class-specific dictionary D c while others fixed. This process is repeated until convergence. This approach is not only highly time consuming but also inaccurate.We will see this in a small example presented in Section 3.4.2. We refer this original FDDL dictionary update as O-FDDL-D.We propose here an efficient algorithm for updating dictionary called E-FDDL-D where the total dictionary D will be optimized when X is fixed, significantly reducing the computational cost.Concretely, when we fix X in equation (3.3), the problem of solving D becomes:D = arg min D f Y,X (D) (3.8)Therefore, D can be solved by using the following lemma. Lemma 1. The optimization problem (3.8) is equivalent to:D = arg min D {−2trace(ED T ) + trace(FD T D)},(3.9)where E = YM(X T ) and F = M(XX T ).Proof: See Appendix B.1.The problem (3.9) can be solved effectively by Online Dictionary Learning (ODL) method  #b35 .

Efficient FDDL sparse coefficient update (E-FDDL-X)
When D is fixed, X will be found by solving:X = arg min X h(X) + λ 1 X 1 ,(3.10)where h(X) = 1 2 f Y,D (X) + λ 2 2 g(X). The problem (3.10) has the form of equation (3.2), and can hence be solved by FISTA  #b41 . We need to calculate gradient of f (•) and g(•) with respect to X.Lemma 2. Calculating gradient of h(X) in equation (2) ∂ 1 2 f Y,D (X) ∂X = M(D T D)X − M(D T Y), (3.11) ∂ 1 2 g(X) ∂(X) = 2X + M − 2 M 1 M 2 . . . M c M .(3.12)Then we obtain: Since the proposed LRSDL is an extension of FDDL, we can also extend these two above algorithms to optimize LRSDL cost function as follows.∂h(X) ∂X = (M(D T D) + 2λ 2 I)X − M(D T Y) + λ 2 (M − 2 M).

LRSDL dictionary update (LRSDL-D)
Returning to our proposed LRSDL problem, we need to find D = [D, D 0 ] when X is fixed. We propose a method to solve D and D 0 separately. For updating D 0 , we use the following lemma:For updating D, recall the observation that f Y (D, X) = f Y (D, X), with Y Y − D 0 X 0 (see equationLemma 3. When D, X in (3.5) are fixed,J Y,D,X (D 0 , X 0 ) = V − D 0 X 0 2 F + λ 2 2 X 0 − M 0 2 F + +η D 0 * + λ 1 X 0 1 + constant, (3.15) where V = Y − 1 2 DM(X). Proof: See Appendix B.3.Based on the Lemma 3, D 0 can be updated by solving:D 0 = arg min D 0 trace(FD T 0 D 0 ) − 2trace(ED T 0 ) + η D 0 * where: E = V(X 0 ) T ; F = X 0 (X 0 ) T (3.16)using the ADMM  #b43  method and the singular value thresholding algorithm  #b71 . The ADMM procedure is as follows. First, we choose a positive ρ, initialize Z = U = D 0 , then alternatively solve each of the following subproblems until convergence:D 0 = arg min D 0 −2trace(ED T 0 ) + trace FD T 0 D 0 , (3.17) with E = E + ρ 2 (Z − U); F = F + ρ 2 I, (3.18) Z =D η/ρ (D c + U), (3.19) U =U + D 0 − Z,(3.20)where D is the shrinkage thresholding operator  #b71 . The optimization problem (3.17) can be solved by ODL  #b35 . Note that (3.18) and (3.20) are computationally inexpensive.

LRSDL sparse coefficients update (LRSDL-X)
In our preliminary work  #b72 , we proposed a method for effectively solving X and X 0 alternatively, now we combine both problems into one and find X by solving the following optimization problem:X = arg min X h(X) + λ 1 X 1 . (3.21) where h(X) = 1 2 f Y,D (X) + λ 2 2 g(X). We again solve this problem using FISTA  #b41  with the gradient of h(X):∇h(X) =    ∂h X 0 (X) ∂X ∂h X (X 0 ) ∂X 0    . (3.22)For the upper term, by combining the observationh X 0 (X) = 1 2 f Y,D,X 0 (X) + λ 2 2 g X 0 (X), = 1 2 f Y,D (X) + λ 2 2 g(X) + constant,(3.23)and using equation, we obtain:∂h X 0 (X) ∂X = (M(D T D) + 2λ 2 I)X − M(D T Y) + λ 2 (M − 2 M). (3.24)For the lower term, by using Lemma 3, we have:h X (X 0 ) = V − D 0 X 0 2 F + λ 2 2 X 0 − M 0 2 F + constant. (3.25) ⇒ ∂h X (X 0 ) ∂X 0 = 2D T 0 D 0 X 0 − 2D T 0 V + λ 2 (X 0 − M 0 ), = (2D T 0 D 0 + λ 2 I)X 0 − 2D T 0 V − λ 2 M 0 . (3.26)By combining these two terms, we can calculate (3.22).Having ∇h(X) calculated, we can update X by the FISTA algorithm  #b41  as given in Algorithm 1. Note that we need to compute a Lipschitz coefficient L of ∇h(X). The overall algorithm of LRSDL is given in Algorithm 2.

Efficient solutions for other dictionary learning methods
We also propose here another efficient algorithm for updating dictionary in two other well-known dictionary learning methods: DLSI  #b42  and COPAR [3].The cost function J 1 (D, X) in DLSI is defined as:C c=1 ||Y c − D c X c 2 F + λ X c 1 + η 2 C j=1,j =c D T j D c 2 F (3.27)Each class-specific dictionary D c is updated by fixing others and solve:D c = arg min Dc Y c − D c X c 2 F + η AD c 2 F , (3.28) with A = D 1 , . . . , D c−1 , D c+1 , . . . , D C T .The original solution for this problem, which will be referred as O-FDDL-D, updates each column d c,j of D c one by one based on the procedure:u = ( x j c 2 2 I + ηA T A) −1 (Y c − i =j d c,i x i c )x j c ,(3.

29)
Algorithm 2 LRSDL sparse coefficients update by FISTA  #b41  function (X,X 0 ) = LRSDL X(Y, D, D 0 , X, X 0 , λ 1 , λ 2 ).

Calculate:
A = M(D T D) + 2λ 2 I; B = 2D T 0 D 0 + λ 2 I L = λ max (A) + λ max (B) + 4λ 2 + 1 1 2. Initialize W 1 = Z 0 = X X 0 , t 1 = 1, k = 1while not convergence and k < k max do 3. Extract X, X 0 from W k .4. Calculate gradient of two parts:M = µ(X), M c = µ(X c ), M = [M 1 , . . . , M C ]. V = Y − 1 2 DM(X) G = AX − M(D T (Y − D 0 X 0 )) + λ 2 (M − M) BX 0 − D T 0 V − λ 2 µ(X 0 ) 5. Z k = S λ 1 /L (W k − G/L) (S α () is the element-wise soft thresholding function. S α (x) = sgn(x)(|x| − α) + ). 6. t k+1 = (1 + 1 + 4t 2 k )/2 7. W k+1 = Z k + t k −1 t k+1 (Z k − Z k−1 ) 8. k = k + 1 end while 9. OUTPUT: Extract X, X 0 from Z k . end function d c,j = u/ u 2 2 ,(3.30)where d c,i is the i-th column of D c and x j c is the j-th row of X c . This algorithm is highly computational since it requires one matrix inversion for each of k c columns of D c . We propose one ADMM  #b43  procedure to update D c which requires only one matrix inversion, which will be referred as E-DLSI-D. First, by letting E = Y c (X c ) T Algorithm 3 LRSDL algorithm function (X,X 0 ) = LRSDL(Y, λ 1 , λ 2 , η).1. Initialization X = 0, and:(D c , X c c ) = arg min D,X 1 2 Y c − DX 2 F + λ 1 X 1 (D 0 , X 0 ) = arg min D,X 1 2 Y − DX 2 F + λ 1 X 1while not converge do 2. Update X and X 0 by Algorithm 1. 3. Update D by ODL  #b35 :E = (Y − D 0 X 0 )M(X T ) F = M(XX T ) D = arg min D {−2trace(ED T ) + trace(FD T D)} 4.Update D 0 by ODL  #b35  and ADMM  #b43  (see equations (3.17) -(3.20)). end while end function and F = X c (X c ) T , we rewrite (3.28) in a more general form:D c = arg min Dc trace(FD T c D c ) − 2trace(ED T c ) + η AD c 2 F . (3.31)In order to solve this problem, first, we choose a ρ, let Z = U = D c , then alternatively solve each of the following sub problems until convergence:D c = arg min Dc −2trace(ED T c ) + trace FD T c D c ,(3.32)with E = E + ρ 2 (Z − U); F = F + ρ 2 I. (3.33) Z =(2ηA T A + ρI) −1 (D c + U). (3.34) U =U + D c − Z. (3.35)This efficient algorithm requires only one matrix inversion. Later in this chapter, we will both theoretically and experimentally show that E-DLSI-D is much more efficient than O-DLSI-D  #b42 . Note that this algorithm can be beneficial for two subproblems of updating the common dictionary and the particular dictionary in COPAR [3] as well.

Online Dictionary Learning (ODL)
We start with the well-known Online Dictionary Learning  #b35  whose cost function is:J(D, X) = 1 2 Y − DX 2 F + λ X 1 . (3.36)where Y ∈ R d×n , D ∈ R d×k , X ∈ R k×n . Most of dictionary learning methods find their solutions by alternatively solving one variable while fixing others. There are two subproblems:

Update X (ODL-X)
When the dictionary D is fixed, the sparse coefficient X is updated by solving the problem:X = arg min X 1 2 Y − DX 2 F + λ X 1 (3.37)using FISTA  #b41 . In each of q iterations, the most computational task is to compute D T DX − D T Y where D T D and D T Y are precomputed with complexities k 2 d and kdn, respectively. The matrix multiplication (D T D)X has complexity k 2 n. Then, the total complexity of ODL-X is:k 2 d + kdn + qk 2 n = k(kd + dn + qkn).(3.38)

Update D (ODL-D)
After finding X, the dictionary D will be updated by:D = arg min D −2trace(ED T ) + trace(FD T D),(3.39)subject to: d i 2 ≤ 1, with E = YX T , and F = XX T . Each column of D will be updated by fixing all others:u ← 1 F ii (e i − Df i ) − d i ; d i ← u max(1, u 2 ) ,where d i , e i , f i are the i−th columns of D, E, F and F ii is the i−th element in the diagonal of F. The dominant computational task is to compute Df i which requires dk operators. Since D has k columns and the algorithm requires q iterations, the complexity of ODL-D is qdk 2 .

Dictionary learning with structured incoherence (DLSI)
DLSI  #b42  proposed a method to encourage the independence between bases of different classes by minimizing coherence between cross-class bases. The cost function J 1 (D, X) of DLSI is defined as (3.27).

Update X (DLSI-X)
In each iteration, the algorithm solves C subproblems:X c = arg min X c Y c − D c X c 2 F + λ X c 1 (3.40)with Y c ∈ R d×n , D c ∈ R d×k , and X c ∈ R k×n . Based on (3.38), the complexity of updating X (C subproblems) is:Ck(kd + dn + qkn). (3.41)

Original update D (O-DLSI-D)
For updating D, each sub-dictionary D c is solved via (3.28). The main step in the algorithm is stated in (3.29) and (3.30). The dominant computational part is the matrix inversion which has complexity d 3 . Matrix-vector multiplication and vector normalization can be ignored here. Since D c has k columns, and the algorithm requires q iterations, the complexity of the O-DLSI-D algorithm is Cqkd 3 . + Cqdk(qk + k) 2.52 × 10 10 O-FDDL-X C 2 k(dn + qCkn + Cdk) 1.51 × 10 11 E-FDDL-X C 2 k(dn + qCnk + dk) 1.01 × 10 11 O-FDDL-D Cdk(qk + C 2 n)10 11 E-FDDL-D Cdk(Cn + Cqk) + C 3 k 2 n 2.8 × 10 10

Efficient update D (E-DLSI-D)
Main steps of the proposed algorithm are presented in equations (3.32)-(3.35) where (3.33) and (3.35) require much less computation compared to (3.32) and (3.34). The total (estimated) complexity of efficient D c update is a summation of two terms: i) q times (q iterations) of ODL-D in (3.32). ii) One matrix inversion (d 3 ) and q matrix multiplications in (3.34). Finally, the complexity of E-DLSI-D is:  Table 3.2.C(q 2 dk 2 + d 3 + qd 2 k) = Cd 3 + Cqdk(qk + d).

Separating the particularity and the commonality dictionary learning (COPAR)


Cost function
COPAR [3] is another dictionary learning method which also considers the shared dictionary (but without the low-rank constraint). By using the same notation as in LRSDL, we can rewrite the cost function of COPAR in the following form:1 2 f 1 (Y, D, X) + λ X 1 + η C c=0 C i=0,i =c D T i D c 2 F , where f 1 (Y, D, X) = C c=1 r 1 (Y c , D, X c ) and r 1 (Y c , D, X c ) is defined as Y c − DX c 2 F + Y c − D 0 X 0 c − D c X c c 2 F + C j=1,j =c X j c 2 F .

Update X (COPAR-X)
In sparse coefficient update step, COPAR [3] solve X c one by one via one l 1 -norm regularization problem:X = arg miñX Ỹ −DX 2 F +λ X 1 ,whereỸ ∈ Rd ×n ,D ∈ Rd ×k ,X ∈ R (k×n ,d = 2d + (C − 1)k andk = (C + 1)k (details can be found in Section 3.1 of [3]). Following results in Section 3.3.1.1 and supposing that C 1, q 1, n ≈ k d, the complexity of COPAR-X is:Ck(kd +dn + qkn) ≈ C 3 k 2 (2d + Ck + qn).

Update D (COPAR-D)
The COPAR dictionary update algorithm requires to solve (C + 1) problems of form (3.31). While O-COPAR-D uses the same method as O-DLSI-D (see equations (3.29-3.30)), the proposed E-COPAR-D takes advantages of E-DLSI-D presented in Section 3.2.5. Therefore, the total complexity of O-COPAR-D is roughly Cqkd 3 , while the total complexity of E-COPAR-D is roughly C(q 2 dk 2 + d 3 + qd 2 k). Here we have supposed C + 1 ≈ C for large C. Table  3.2.

Total complexities of O-COPAR (the combination of COPAR-X and O-COPAR-D) and E-COPAR (the combination of COPAR-X and E-COPAR-D) are summarized in


Fisher discrimination dictionary learning (FDDL)


Original update X (O-FDDL-X)
Based on results reported in DFDL [2], the complexity of O-FDDL-X is roughly C 2 kn(d + qCk) + C 3 dk 2 = C 2 k(dn + qCkn + Cdk).

Efficient update X (E-FDDL-X)
Based on section 3.2.4.2, the complexity of E-FDDL-X mainly comes from equation 

Original update D (O-FDDL-D)
The original dictionary update in FDDL is divided in to C subproblems. In each subproblem, one dictionary D c will be solved while all others are fixed via:D c = arg min Dc Y − D c X c 2 F + Y c − D c X c c 2 F + i =c D c X c i 2 F , = arg min Dc −2trace(ED T c ) + trace(FD T c D c ) complexity: qdk 2 ,(3.44)where:Y = Y − i =c D i X i complexity: (C − 1)dkCn, E = Y(X c ) T + Y c (X c c ) T complexity: d(Cn)k + dnk, F = 2(X c )(X c ) T complexity k(Cn)k.When d k, C 1, complexity of updating D c is:qdk 2 + (C 2 + 1)dkn + Ck 2 n ≈ qdk 2 + C 2 dkn (3.45)Then, complexity of O-FDDL-D is Cdk(qk + C 2 n).

Efficient update D (E-FDDL-D)
Based on Lemma 1, the complexity of E-FDDL-D is: (2D T 0 D 0 + λ 2 I)X 0 − 2D T 0 Y + D T 0 DM(X) − λ 2 M 0 .Therefore, the complexity of LRSDL-X is:(Ck)d(Ck) D T D + (Ck)d(Cn) D T Y + (Ck)dk D T D 0 + kdk D T 0 D 0 + kd(Cn) D T 0 Y + +q      (Ck) 2 (Cn) (M(D T D)+2λ 2 I)X + (Ck)k(Cn) M(D T D 0 X 0 ) + + k 2 Cn (2D T 0 D 0 +λ 2 I)X 0 + k(Ck)(Cn) D T 0 DM(X)      , ≈ C 2 k(dk + dn) + Cdk 2 + qCk 2 n(C 2 + 2C + 1), ≈ C 2 k(dk + dn + qCkn). (3.47)which is similar to the complexity of E-FDDL-X. Recall that we have supposed number of classes C 1.

Update D
Compare to E-FDDL-D, LRSDL-D requires one more computation of Y = Y − D 0 X 0 (see section 3.2.4.3). Then, the complexity of LRSDL-D is:Cdk(Cn + Cqk) + C 3 k 2 n E-FDDL-D + dk(Cn) D 0 X 0 , ≈ Cdk(Cn + Cqk) + C 3 k 2 n,(3.48)which is similar to the complexity of E-FDDL-D.

Update D 0
The algorithm of LRSDL-D0 is presented in section 3.2.4.3 with the main computation comes from (3.16), (3.17) and (3.19). The shrinkage thresholding operator in (3.19) requires one SVD and two matrix multiplications. The total complexity of LRSDL-D0 O-FDDL C 2 dk(n + Ck + Cn)+ +Ck 2 q(d + C 2 n) 2.51 × 10 11E-FDDL C 2 k((q + 1)k(d + Cn) + 2dn) 1.29 × 10 11 O-COPAR C 3 k 2 (2d + Ck + qn) + Cqkd 3 6.55 × 10 12    Table 3.2 compares LRSDL to other stateof-the-art methods. We pick a typical set of parameters with 100 classes, 20 training samples per class, 10 bases per sub-dictionary and shared dictionary, data dimension 500 and 50 iterations for each iterative method. Concretely, C = 100, n = 20, k = 10, q = 50, d = 500. We also assume that in (3.49), q 2 = 50. Table 3.1 shows that all three proposed efficient algorithms require less computation than original versions with most significant improvements for speeding up DLSI-D. Table 3.2 demonstrates an interesting fact. LRSDL is the least expensive computationally when compared with other original dictionary learning algorithms, and only E-FDDL has lower complexity, which is to be expected since the FDDL cost function is a special case of the LRSDL cost function. COPAR is found to be the most expensive computationally.  E-COPAR C 3 k 2 (2d + Ck + qn)+ +Cd 3 + Cqdk(qk + d) 3.38 × 10 11 LRSDL C 2 k((q + 1)k(d + Cn) + 2dn) C 2 dkn + (q + q 2 )dk 2 1.3 × 10 11 is: d(Ck)(Cn) V=Y− 1 2 DM(X) + d(Cn)k E in (3.16) + k(Cn)k F in (3.16) + qdk 2 (3.17) + O(dk 2 ) + 2dk 2 (3.19) , ≈ C 2 dkn + qdk 2 + O(dk 2 ), = C 2 dkn + (q + q 2 )dk 2 , for some q 2 .

Summary


Experimental results
In this section, we apply the proposed models to the problem of classifying objects of interest. Extensive results are presented on simulated and real-life datasets. A MATLAB toolbox for the tensor sparsity methods presented in this chapter is available at  #b104 .    #b105 , which was developed by the U.S. Army Research Laboratory (ARL). The software was validated for a wide variety of radar signature calculation scenarios  #b106  #b107 . Our volumetric rough ground surface grid -with the embedded buried targets -was generated by using the surface root-mean-square (rms) height and the correlation length parameters. The targets are flush buried at 2-3 cm depth. In our experiments, the easiest case of rough ground surface in our experiments, the surface rms is 5.6 mm and the correlation length is 15 cm. The SAR images of various targets and clutter objects are generated from EM data by coherently integrated individual radar return signals along over a range of aspect angles. The SAR images are formed using the backprojection image formation  #b108  with an integration angle of 30 • . Figure 4.4a shows the SAR images (using vertical transmitter, vertical receiver -VV -polarization) of some targets that are buried under a perfectly smooth ground surface. Each target is imaged at a random viewing aspect angle and an integration angle of 30 • . Figures 4.4b  and 4.4c show the same targets as Figure 4.4a, except that they are buried under a rough ground surface (the easiest case corresponds to ground scale/noise level 2 = 1 and harder case corresponds to noise level = 5 . Each data sample of one object is represented by either i) one SAR image using data from one co-pol (VV, HH) channel or ii) two or more images using data from co-pol (VV, HH) and cross-pol (HV) channels. For each target type, we tested 100 image samples measured at random aspect angles.

Comparing methods and datasets
We present the experimental results of applying these methods to five diverse datasets: the Extended YaleB face dataset  #b73 , the AR face dataset  #b74 , the AR gender dataset, the Oxford Flower dataset  #b75 , and two multi-class object category dataset -the Caltech 101  #b76  and COIL-100  #b77 . Example images from these datasets are shown in Figure 3.4. We compare our results with those using SRC [1] and other state-of-the-art dictionary learning methods: LC-KSVD  #b36 , DLSI  #b42 , FDDL [4], COPAR [3], D 2 L 2 R 2  #b44 , DLRD  #b78 , JDL  #b32 , and SRRS  #b79 . Regularization parameters in all methods are chosen using five-fold cross-validation  #b67 . For each experiment, we use 10 different randomly split training and test sets and report averaged results.For two face datasets, feature descriptors are random faces, which are made by projecting face images onto a random vector using a random projection matrix. As  in  #b80 , the dimension of a random-face feature in the Extended YaleB is d = 504, while the dimension in AR face is d = 540. Samples of these two datasets are shown in Figure  3.4a) and b).For the AR gender dataset, we first choose a non-occluded subset (14 images per person) from the AR face dataset, which consists of 50 males and 50 females, to conduct experiment of gender classification. Training images are taken from the first 25 males and 25 females, while test images comprises all samples from the remaining 25 males and 25 females. PCA was used to reduce the dimension of each image to 300. Samples of this dataset are shown in Figure 3.4c).The   extractor  #b81  to obtain feature vectors of dimension 10,000. The test set consists of 20 images per class, the remaining 60 images per class are used for training. Samples of this dataset are shown in Figure 3.4d).For the Caltech 101 dataset, we use a dense SIFT (DSIFT) descriptor. The DSIFT descriptor is extracted from 25 × 25 patch which is densely sampled on a dense grid with 8 pixels. We then extract the sparse coding spatial pyramid matching (ScSPM) feature  #b82 , which is the concatenation of vectors pooled from words of the extracted DSIFT descriptor. Dimension of words is 1024 and max pooling technique is used with pooling grid of 1 × 1, 2 × 2, and 4 × 4. With this setup, the dimension of ScSPM feature is 21,504; this is followed by dimension reduction to d = 3000 using PCA.The COIL-100 dataset contains various views of 100 objects with different lighting conditions. Each object has 72 images captured from equally spaced views. Similar to the work in  #b79 , we randomly choose 10 views of each object for training, the rest is used for test. To obtain the feature vector of each image, we first convert it to grayscale, resize to 32 × 32 pixel, vectorize this matrix to a 1024-dimensional vector, and finally normalize it to have unit norm.Samples of this dataset are shown in Figure 3.4e).

Validation of efficient algorithms
To evaluate the improvement of three efficient algorithms proposed in section 3.2, we apply these efficient algorithms and their original versions on training samples from the AR face dataset to verify the convergence speed of those algorithms. In this example, number of classes C = 100, the random-face feature dimension d = 300, number of training samples per class n c = n = 7, number of atoms in each particular dictionary k c = 7.  

E-FDDL-D and E-FDDL-X


E-DLSI-D and E-COPAR-D


Visualization of learned shared bases
To demonstrate the behavior of dictionary learning methods on a dataset in the presence of shared features, we create a toy example in Figure 3.8. This is a classification problem with 4 classes whose basic class-specific elements and shared elements are visualized in Figure 3.8a). Each basis element has dimension 20 pixel×20 pixel. From these elements,  we generate 1000 samples per class by linearly combining class-specific elements and shared elements followed by noise added; 200 samples per class are used for training, 800 remaining images are used for testing. Samples of each class are shown in Figure 3.8b). Figure 3.8c) show sample learned bases using DLSI  #b42  where shared features are still hidden in class-specific bases. In LC-KSVD bases (Figure 3.8d) and e)), shared features (the squared in the middle of a patch) are found but they are classified as bases of class 1 or class 2, diminishing classification accuracy since most of test samples are classified as class 1 or 2. The same phenomenon happens in FDDL bases (Figure 3.8f)).The best classification results happen in three shared dictionary learnings (COPAR [3] in Figure 3.8g), JDL  #b32  in Figure 3.8h) and the proposed LRSDL in Figure 3.8i)) where the shared bases are extracted and gathered in the shared dictionary. However, in COPAR and JDL, shared features still appear in class-specific dictionaries and the shared dictionary also includes class-specific features. In LRSDL, class-specific elements and shared elements are nearly perfectly decomposed into appropriate sub dictionaries. The reason behind this phenomenon is the low-rank constraint on the shared dictionary  of LRSDL. Thanks to this constraint, LRSDL produces perfect results on this simulated data.

Effect of the shared dictionary sizes on overall accuracy
We perform an experiment to study the effect of the shared dictionary size on the overall classification results of three shared dictionary methods: COPAR [3], JDL  #b32  and LRSDL in the AR gender dataset. In this experiment, 40 images of each class are used for training. The number of shared dictionary bases varies from 10 to 80. In LRSDL, because there is a regularization parameter η which is attached to the low-rank term (see equation (3.5)), we further consider three values of η: η = 0, i.e. no low-rank constraint, η = 0.01 and η = 0.1 for two different degrees of emphasis. Results are shown in Figure  3.9.We observe that the performance of COPAR heavily depends on the choice of k 0 and its results worsen as the size of the shared dictionary increases. The reason is that when k 0 is large, COPAR tends to absorb class-specific features into the shared dictionary. This trend is not associated with LRSDL even when the low-rank constraint is ignored (η = 0), because LRSDL has another constraint ( X 0 − M 0 2 F small) which forces the coefficients corresponding to the shared dictionary to be similar. Additionally, when we increase η, the overall classification of LRSDL also gets better. These observations confirm that our two proposed constraints on the shared dictionary are important, and the LRSDL exhibits robustness to parameter choices. For JDL, we also observe that its performance is robust to the shared dictionary size, but the results are not as good as those of LRSDL. Table 3.3 shows overall classification results of various methods on all presented datasets in terms of mean ± standard deviation. It is evident that in most cases, three dictionary learning methods with shared features (COPAR [3], JDL  #b32  and our proposed LRSDL) outperform others with all five highest values presenting in our proposed LRSDL. Note that JDL method represents the query sample class by class. We also extend this method by representing the query sample on the whole dictionary and use the residual for classification as in SRC. This extended version of JDL is called JDL*.

Performance of LRSDL with varied parameters


Run time of different dictionary learning methods
Finally, we compare training and test time per sample of different dictionary learning methods on the Oxford Flower dataset. Note that, we use the efficient FDDL, DLSI, COPAR in this experiment. Results are shown in Table 3.4. This result is consistent with the complexity analysis reported in Table 3.2 with training time of LRSDL being around half an hour, 10 times faster than COPAR [3] and also better than other low-rank models, i.e. D 2 L 2 R 2  #b44 , and SRRS  #b79 .

SAR geometry and image formation overview
P i = N i 2 k=N i 1 w k * s k (f (i, k)), (4.1)where N i 2 − N i 1 + 1 is the total number of aperture records used for the coherent integration, w k is the weighting value at the k th aperture position, and f (i, k) is the shift index to the signal s k for i th pixel at the k th aperture position. For a typical SAR image with 0 • aspect angle, N i 1 and N i 2 correspond to the angle values of −α/2 and α/2 to form a SAR image with an integration angle of α. Note that for a true constant integration angle SAR image formation, N i 1 and N i 2 are computed for every pixel of the SAR image. However, for computational efficiency, a large image area is divided into smaller subimages. For each subimage, SAR image formation is computed using the N i 1 and N i 2 values derived from the geometry of the center of the subimage and the radar aperture. To exploit the aspect dependence information of target, instead of forming a single SAR image with 0 • aspect angle as To achieve a constant cross-range resolution SAR image, a large image area is also divided into smaller subimages. Each subimage is formed using a different subset of aperture. For a constant integration angle, subimages at farther range would be integrated using a longer aperture than near-range subimages. The subimages are then mosaicked together to form a single large image that covers the area of interest. In consecutive multi-look SAR image processing mode, instead of generating a single SAR image, multiple SAR images are formed at different viewing angles to exploit the aspect angle dependent information from targets. Thus, each aperture for each subimage is further divided into smaller segments (either disjoint or overlapped) that are used to form consecutive multilook SAR images as illustrated in Figure 4.1. The aspect angle dependence features from targets have been exploited in past research before using different techniques  #b88  #b89  #b90 .

Closely related works and motivation
UWB radar techniques have recently attracted increasing attention in the area of penetration and object detection, thanks to their usage in security applications and surveillance systems  #b91 . T. Sakamoto et al.  #b92  proposed fast methods for ultrawideband (UWB) radar imaging that can be applied to a moving target. The technology has been also applied to 3-D imaging applications  #b93 , human posture  #b94 , human activity  #b95 , vital sign  #b96 , and liquid material  #b97  classification problems. In these papers, due to high dimensionality and small signal-to-ratio (SNR), the signals need to be preprocessed, e.g., dimensionality reduction and background subtraction, before being used to train a classifier. It has been shown that support vector machines usually provide the best performance  #b95  #b97 . It is worth noting that in the aforementioned applications, objects are usually big (human) and captured from a relatively small distance. On the contrary, objects in our problem are relatively small and quite far from the radar.In this chapter, we consider the problem of discriminating and classifying buried targets of interest (metal and plastic mines, 155-mm unexploded ordinance [UXO], etc.) from other natural and manmade clutter objects (a soda can, rocks, etc.) in the presence of noisy responses from the rough ground surfaces for low-frequency UWB 2-D SAR images. For classification problems, sparse representation-based classification [1] (SRC) has been successfully demonstrated in other imagery domains such as medical image classification [2, #b18  #b19  #b46 , hyperspectral image classification  #b20  #b21  #b22 , high-resolution Xband SAR image classification  #b23 , video anomaly detection  #b25 , and several others [5, 27-30, 73, 99, 100]. However, in the low-frequency RF UWB SAR domain, although we have studied the feasibility of using SRC for higher-resolution 3-D down-looking SAR imagery  #b100 , the application of SRC to low-frequency UWB 2-D SAR imagery has not been studied to date due to the aforementioned low-resolution issue. In this chapter, we generalize the traditional SRC to address target classification using either a single channel (radar polarization) or multiple channels of SAR imagery. Additionally, we further propose a novel discriminative tensor sparsity framework for multi-look multichannel classification problem, which is naturally suitable for our problem. In sparse representations, many signals can be expressed by a linear combination of a few basic elements taken from a "dictionary". Based on this theory, SRC [1] was originally developed for robust face recognition. The main idea in SRC is to represent a test sample as a linear combination of samples from the available training set. Sparsity manifests because most of the nonzero components correspond to basic elements with the same class as the test sample.Multi-channel SRC has been investigated before in medical images  #b19  #b46 . In these papers, one dictionary for each channel is formed from training data with locations of all channels of one training point being the same in all dictionaries. Then intuitively, when sparsely encoding each channel of a new test point using these dictionaries, we obtain sparse codes whose active (nonzero) elements tend to happen at the same locations in all channels. In other words, active elements are simultaneously located at the same location across all channels. This intuition is formulated based on l 0 pseudo-norm, which is solved using a modified version of simultaneous orthogonal matching pursuit (SOMP)  #b101 . The cost function is nonconvex, and hence, it is difficult to find the global solution. Furthermore, when more constraints involved, there is no straightforward way to extend the algorithm. In this chapter, we proposed another way of formulating the simultaneity constraint based on the l 12 norm, which enforces the row sparsity of the code matrix (in tensor form, we call it tube sparsity). The newly convex optimization problem can be solved effectively using the fast iterative shrinkage thresholding algorithm (FISTA)  #b41 . We also propose other different tensor sparsity models for our multi-channel classification problems.It has been shown that learning a dictionary from the training samples instead of concatenating all of them as a dictionary can further enhance performance of sparsitybased methods. On one hand, the training set can be compacted into a smaller dictionary, reducing computational burden at the test time. On the other hand, by using dictionary learning, discriminative information of different classes can be trained via structured discriminative constraints on the dictionary as well as the sparse tensor code. A comprehensive study of discriminative dictionary learning methods with implementations is presented at [5, #b102 . These dictionary learning methods, however, are all applied to single-channel problem where samples are often represented in form of vectors. While multi-channel signals can be converted to a long vector by concatenating all channels, this trivial modification not only leads to the curse of dimensionality of high-dimensional space, but also possibly neglects cross-channel information, which might be crucial for classification. In this chapter, we also propose a method named TensorDL, which is a natural extension of single-channel dictionary learning frameworks to multi-channel dictionary learning ones. Particularly, the cross-channel information will be captured using the aforementioned simultaneity constraint.Naturally, when a radar carried by a vehicle or aircraft moves around an object of interest, it can capture multiple consecutive views of that object (see Fig. 4.1). Consequently, if the multi-look information is exploited, the classification accuracy will be improved. While the multi-look classification problem has been approached before by SRC-related methods  #b23  #b98 , none of these works uses the relative continuity of different views. We propose a framework to intuitively exploit this important information. More importantly, the optimization problem corresponding to this structure can be converted to the simultaneous sparsity model by using an elegant trick that we call ShiftSRC. Essentially, a tensor dictionary is built by circularly shifting an appropriate amount of a singlechannel dictionary. When we sparsely code the multi-look signals using this tensor dictionary, the tensor sparse code becomes tube sparsity.

2.
A generalized tensor discriminative dictionary learning (TensorDL) is also proposed when more training data involved. These dictionary learning frameworks are shown to be robust even with high levels of noise.

3.
A relative SRC framework (ShiftSRC) is proposed to deal with multi-look data. Low-frequency UWB SAR signals are often captured at different views of objects, depending on the movement of the radar carriers. These signals contain uniquely important information of consecutive views. With ShiftSRC, this information will be comprehensively exploited. Importantly, a solution to the ShiftSRC framework can be obtained by an elegant modification on the training dictionary, resulting in a tensor sparse coding problem, which is similar to a problem proposed in contribution 1).The remainder of this chapter is organized as follows. Section II presents different tensor sparsity frameworks and the discriminative tensor dictionary learning scheme for multichannel classification problems. The ShiftSRC for multiple-relative-look and solutions to all proposed frameworks are also presented in this section. Section III shows extensive experimental results on a simulated dataset for several scenarios. An experiment with a realistic dataset is also included. Section IV concludes the chapter.

Sparse representation-based classification 4.2.1 Notation
Scalars are denoted by italic letters and may be either lower or uppercase, e.g., d, N, k.Vectors and matrices are denoted by bold lowercase (x, y) and bold upper case (X, Y), respectively. In this chapter, we also consider 3-D tensors (tensors for short) whose dimensions are named row, column, and channel. A tensor with only one column will be denoted by a bold, lowercase, calligraphic letter (x, y). Tensors with more than one column will be denoted by an bold, uppercase, calligraphic letters (X , Y, D).For any tensor M, let M (t) be its t-th channel. For convenience, given two tensors M, N , the tensor multiplication P = MN is considered channel-wise multiplication, i.e., P (t) = M (t) N (t) . For a tensor M, we also denote the sum of square of all elements by M 2 F and the sum of absolute values of all elements by M 1 . Tensor addition/subtraction simply represents element-wise addition/subtraction. Each target sample is represented by a UWB SAR image formed using either a single (using co-pol) or multiple polarization (using both co-pol and cross-pol) channels. Thus, one target sample is denoted by y ∈ R d×1×T , where d is the total number of image pixels and T is the number of polarization channels. A collection of N samples is denoted byY ∈ R d×N ×T .Consider a general classification problem with C different classes. Let D c (1 ≤ c ≤ C) be the collection of all training samples from class c, D 0 be the collection of samples in the shared class, and D = [D 1 , . . . , D C , D 0 ] be the total dictionary with the concatenation being done at the second dimension (column). In our problem, the shared class can be seen as the collection of ground images.

Classification scheme
Using the definition of tensor multiplication, a sparse representation of y using D can be obtained by solvingx = arg min x 1 2 y − Dx 2 F + λg(x) (4.2)where λ is a positive regularization parameter and g(x) is a function that encourages x to be sparse. Denote by x i the sparse coefficient of y on D i . Then, the tensor x can be divided into C + 1 tensor parts x 1 , x 2 , . . . , x C , x 0 .After solving the sparse coding problem (4.2), shared features (grounds in our problem) are eliminated by takingȳ = y − D 0 x 0 . Then the identity of one sample y can be determined by the dictionary that provides the minimum residual:identity(y) = min i∈{1,2,...,C} ȳ − D i x i 2 2 (4.3)Confuser detection: In practical problems, the set of confusers is not limited to the training set. A confuser can be anything that is not a target; it can be solely the ground or a capture of an unseen object. In the former case, the test signal can be well represented by using only the ground D 0 , while in the latter case, the sparse representation assumption is no longer valid. Therefore, one test signal y is classified as a confuser if one of following three conditions is satisfied: i) it is not sparsely interpreted by the total dictionary D; ii) it has the most active elements in the sparse code locating at x 0 ; and iii) it is similar to known confusers.  

Generalized sparse representation-based classification
In SRC [1] where only one channel is considered, g(x) is simply a function that forces sparsity as l 0 -or l 1 -minimization. l 1 -minimization is often used since it leads to a convex optimization problem with tractable solutions. In the following, we present two natural extensions of SRC for multi-channel cases. We also proposed two tensor sparse representation methods that can enhance classification accuracy by exploiting cross-channel information. These four generalized SRC methods are as follows.a) Apply a sparsity constraint on each column of the coefficient tensor x, no cross-channel constraint.We can see that this is similar to solving T separate sparse coding problems, each for a polarization channel. The classification rule is executed based on the sum of all the squares of the residuals. We refer to this framework as SRC-cumulative residual or SRC-CR (CR in the short version). (See Figure 4.2a with sparse tensor x 1 ). The sparse code corresponding to the t th channel, x (t) , is computed via the traditional l 1 -minimization:x (t) = arg minx (t) 1 2 y (t) − D (t) x (t) 2 2 + λ x (t) 1 (4.4)which can be solved effectively using FISTA  #b41 , ADMM  #b43 , etc., algorithms or the SPAMS toolbox  #b66 .b) Concatenate all channels.The most convenient way to convert a multi-channel problem to a single-channel problem is to concatenate all T channels of one signal to obtain a long vector. By doing so, we have the original SRC framework with l 1 -norm minimization. After solving the sparse coding problem, if we break the long vectors and rearrange them back to tensor forms, then the tensor sparse coefficients x can be formed by replicating the one-channel sparse coefficient at all channel (see Figure 4.2b with sparse tensor x 2 ). From this tensor viewpoint, the code tensor x will have few active "tubes"; moreover, all elements in a tube are the same. We refer to this framework as SRC-concatenation or SRC-CC (CC in the short version).The optimization problem in SRC-CC and its solution are very straightforward. First, we stack all channel dictionaries into a long one:D = [D (1) ; D (2) ; . . . ; D (T ) ] (symbol ';' represents the concatenation in the first dimension). Then for every test signal, we also stack all of its channels to form a long vector:ŷ = [y (1) ; y (2) ; . . . ; y (T ) ]. The optimization problem (4.2) becomes the traditional l 1 regularization problem:x = arg min x 1 2 ŷ −Dx 2 2 + λ x 1 (4.5)then also can be solved by aforementioned methods.

c) Use a simultaneous model.
Similar to the SHIRC model proposed in  #b19  #b46 , we can impose one constraint on active elements of tensor x as follows:x also has few nonzero tubes as in SRC-CC; however, elements in one active tube are not necessarily the same. In other words, the locations of nonzero coefficients of training samples in the linear combination exhibit a one-toone correspondence across channels. If the j-th training sample in D (1) has a nonzero contribution to y (1) , then for t ∈ {2, . . . , T }, y (t) also has a nonzero contribution from the j-th training sample in D (t) . We refer to this framework as SRC-Simultaneous or SRC-SM (SM in the short version). (See Figure 4.2c with sparse tensor x 3 ). To achieve this requirement, we can impose on the tensor x 3 (with one column and T channels) the l 1,2 -minimization constraint, which is similar to the row-sparsity constraint applied on matrices in  #b23 .Remarks: While SHIRC uses l 0 -minimization on x and applies the modified SOMP  #b101 , our proposed SRC-SM exploits the flexibility of l 1,2 -regularizer since it is convex, and easily modified when more constraints are present (e.g., non-negativity). In addition, it is more efficient especially when dealing with problems of multiple samples at input.Concretely, the optimization problem of SRC-SM can be written in the formx = arg min x 1 2 y − Dx 2 F + λ K k=1vec(x k:: ) 2 (4.6) where x k:: denotes the k th tube of the tensor code x and K is the total column of the dictionary D, and vec(x k:: ) is the vectorization of the tube x k:: . This problem is similar to the joint sparse representation (JSRC) problem proposed in  #b23  except that SRC-SM enforces tube-sparsity instead of the row-sparsity. Details of the algorithm that solves are described in Section 4.2.6.

d) Use a group tensor model.
Intuitively, since one object is ideally represented by a linear combination of the corresponding dictionary and the shared dictionary, it is highly likely that number of active (tensor) parts in x is small, i.e., most of x 1 , . . . , x C , x 0 are zero tensors. This suggests us a group tensor sparsity framework as an extension of  #b61  that can improve the classification performance, which is referred to as SRC-GT (GT in the short version). The visualization of this idea is shown in Figure 4.2d.The optimization problem of SRC-GT is similar to (4.2.3) with a slight difference in the grouping coefficients:x = arg min x 1 2 y − Dx 2 F + λ C+1 c=1 vec(x c ) 2 (4.7)where C + 1 is the total number of classes (including the shared ground class), and vec(x c ) is the vectorization of the group tensor x c . Solution to this problem will be discussed next.The overall algorithm of generalized SRC applied to multi-channel signals in the presence of a shared class is shown in Algorithm 4.

Dictionary learning for tensor sparsity
As a natural extension, we can extend the tensor sparsity models to dictionary learning ones. Most of dictionary learning methods focus on a single-channel signal, which is not suitable for models with cross-channel information. In this work, we extend single-channel dictionary learning methods to multi-channel dictionary ones by applying aforementioned tensor sparsity constraints.In single-channel, most of discrimination dictionary learning methods, such as FDDL [4], DLSI  #b42 , DFDL [2], LRSDL [5], etc., have a cost function that is of the formJ Y (D, X) =f Y (D, X) + λḡ(X) (4.9)whereḡ(X) is a function enforcing the sparsity of X, andf Y (D, X), which includes fidelity and discriminant terms, is a function of D, X and depends on the training samples Y.One straightforward extension of these single-channel models to a multi-channel case is to apply the first term f Y (D, X) to each channel and join all channels by a sparsity constraint represented by g(X). Naturally, g(X) can be one of four presented crosschannel sparsity constraints. Concretely, the overall cost function would be in the formJ Y (D, X ) = f Y (D, X ) + λg(X ) (4.10)Algorithm 4 Generalized SRC with a shared class function identity(y) = GENERALIZED SRC(y, D, λ, g(•), ε, τ ) INPUT: y ∈ R d×1×T -a test sample; D = [D 1 , D 2 , . . . , D C , D 0 ] ∈ R d×K×T -the total dictionary with the shared dictionary D 0 ; g(•) -the sparsity constraint imposed on sparse codes. λ ∈ R + -a positive regularization parameter; ε, τ -positive thresholds.OUTPUT: the identity of y.1. Sparsely code y on D via solving:x = arg min x { y − Dx 2 F + λg(x)} (4.8) 2.Remove the contribution of the shared dictionary:y = y − D 0 x 0 .3. Calculate the class-specific residuals :r c = ȳ − D c x c 2 , ∀c = 1, 2, . . . , C.

Decision:
if min c (r c ) > τ (an unseen object) or ȳ 2 < ε (a ground) then y is a confuser. else identity(y) = arg minc {r c } end if end function where f Y (t) (D (t) , X (t) ) =f Y (t) (D (t), X (t) ) and g(X ) is one of {CR, CC, SM, GT} sparsity constraints.In this chapter, we particularly focus on extending FDDL [4] to the multi-channel case. FDDL is a special case of LRSDL [5] without an explicit shared dictionary. FDDL is chosen rather than LRSDL since in our problem, the shared dictionary, e.g., grounds, is already separated out. We also adopt fast and efficient algorithms proposed in the dictionary learning toolbox DICTOL  #b102  to update each channel of the dictionary D. Also, the sparse code tensor X is updated using FISTA  #b41  algorithm, which is discussed in Section 4.2.6.The proposed cross-channel dictionary learning method is named TensorDL suffixed by CR, CC, SM, or GT when different sparsity constraints are applied on X .  

Tensor sparsity with multiple relative looks
In realistic situations, objects might be captured at different angles instead of only one. Moreover, these are often consecutive angles that a plane or a vehicle can capture (see Figure 4.3a left) while moving around objects. Based on this observation, in the training phase, we collect data from different views of objects, as in Figure 4.3a right, and orderly arrange them into dictionaries for each object, as illustrated in Figure 4.3b. The test objects, which are often captured at different relative views y 1 , y 2 , y 3 , are then sparsely coded by the whole dictionary.Intuitively, if x 1 is the sparse code of the first view y 1 with only few active elements, then the sparse code x 2 of the next view y 2 will be active at locations shifted by one. Similarly, active locations in x 3 of the third view will be shifted by two compared to x 1 , and so on. In this case, active coefficients form a "stair", as illustrated in Figure 4.3b right.The sparse coding problem with the "stair" sparsity is a novel problem and has not been addressed before. In this chapter, we propose a method called ShiftSRC to convert this problem to a previously known problem. The central idea is that if we stack all views into a tensor and "circularly shift" the ordered dictionary by one to the left at each view, then the obtained tensor code will be a tensor with active elements forming a "tube" sparsity (see Figure 4.3c). The solution to this problem is similar to the solution of SRC-SM as stated in this chapter.

Solution to optimization problems
Both optimization problems (4.2.3) and (4.7) have the formx = arg min x {F (x) ≡ f (x) + λg(x)},(4.11)where• g(x) is sum of norm 2, then it is a continuous convex function and nonsmooth.• f (x) = 1 2 y − Dx 2 F is a continuous convex function of the type C 1,1 , i.e., continuously differentiable with a Lipschitz continuous gradient L:∇f (x 1 ) − ∇f (x 2 ) F ≤ L x 1 − x 2 F for every x 1 , x 2 .We observe that, with these properties, the optimization problem (4.11) can be solved by FISTA  #b41 . There are three main tasks in FISTA:1. Calculating ∇f (x), which can be easily computed as∇f (x) = D T (Dx − y).where each channel of D T is the transpose of the corresponding channel of D.

Calculating a Lipschitz constant of ∇f (x). For our function f , we can choose
L = max t=1,2,...,T λ max (D (t) ) T D (t) (4.12)where λ max is the maximum eigenvalue of a square matrix.3. Solving a suboptimization problem of the form x = arg minx 1 2 x − u 2 F + ηg(x) (4.13)with η = λ L .Algorithm 5 Tensor sparse coding by FISTA  #b41  function x = TENSOR SC(y, D, x init , λ).

Calculate
A = D T D, b = D T y L = max t=1,2,...,T (λ max (A (t) )) 2. Initialize x 0 = x init , w 1 = x 0 , j = 1, t 1 = 1while non convergence and j < j max do 3. Calculate gradient: g = Aw j − y.4. Calculate u = w j − g/L.5. If SRC-SM, x j is the solution of (4.14); if SRC-GT, x j is the solution of (4.16). Each problem in (4.14) is a minimum l 2 -norm minimization with solution being6. t j+1 = (1 + 1 + 4t 2 j )/2 7. w j+1 = x j +x k:: = max 1 − η vec(u k:: ) 2 , 0 u k:: , ∀k = 1, 2, . . . , K. Similarly, for SRC-GT, problem (4.13) can be written as with solution being:x = arg min x 1 2 x − u 2 F + ηx c = max 1 − η vec(u c ) 2, 0 u c , ∀c = 1, . . . , C + 1. 

Denoised signal visualization
We construct the dictionary D = D t , D c , D c of all three polarizations, with D t , D c , D g being dictionaries of targets, confusers, and grounds, respectively. The sub-dictionary D o = D t , D c can be seen as the dictionary of the objects of interest. For a noisy signal y, we first solve the following problem:x = arg min x y − Dx 2 F + λg(x) (4.18)where g(x) is the proposed SM constraint. The sparse tensor code x is then decomposed into two parts, x o and x g . The latter can be considered coefficients corresponding to the ground dictionary D g . The original signal can be approximately decomposed into two parts: D g x g as separated noise, and D o x o as the denoised signal. Visualization of these signals are shown in Figure 4.5. We can see that the tensor framework successfully decomposes noisy signals into a clean part and a ground signal. These results show the potential of the proposed tensor sparsity frameworks for classification.  

Overall classification accuracy
We apply four methods presented in 4.2.3 to different combinations of three polarizations: VV, HH, VV+HH, HH+HV, and VV+HH+HV (or ALL), and also compare these results with those obtained by a support vector machine (SVM) using the libsvm library  #b68 . SVM was also applied to classify UWB signals  #b95  #b97 . The training set comprises all five target sets, four out of five confuser sets (each time we leave one confuser set out, which is meant to be unseen), and the ground set. While all confuser sets can be seen as one classconfuser class -there are two ways of organizing target sets. First, each of five targets is considered one class in case the identity of each target is crucial (we name this scenario separate-target with five target classes and one confuser class). Second, if we only need to know whether an object of interest is a target or not, we can consider all five targets as one class and its corresponding name is all-target with one target class and one confuser class. We also consider two families of the sparse coding problem, one with and one without the non-negativity constraint on the sparse code x in each of the tensor sparse coding methods. Each experiment is conducted 10 times and their results are reported as the average number. Parameters in each method are chosen by a 5-fold cross-validation procedure. In this experiment, all test samples are corrupted by small noise, i.e., the noise level is set to one. In our experiments, we use overall classification accuracy as the performance metric, which computes percentage of correctly classified samples over total test samples across all classes.Overall classification accuracies of different methods on different polarization combinations are reported in Table 4.1. From the table, a few inferences can be made:• SRC-related methods with non-negative sparse coefficients perform better than those without this constraint 3 . In addition, SVM is outperformed by all other methods in all tasks.• SRC-SM provides the best results in all combinations for both the separate-target and all-target scenarios. The best accuracies in both cases are significantly high with slightly over 90% in the six-class classification problem and nearly 97% in the binary classification problem.• If only one polarization is used, SRC-CR, SRC-CC, and SRC-SM have identical results, since all of them are basically reduced to traditional SRC in this case. Additionally, these three methods slightly outperform SRC-GT in this scenario.• If only one polarization can be obtained, HH always outperforms VV and by a significant margin. Additionally, the HH+VV combination often worsens the results versus using HH alone.• If the same method is used on different combinations, the best results are mostly obtained by the combination of HH and HV polarizations in both the separatetarget and all-target scenarios.

Effect of noise levels on overall accuracy
The results in the previous section are collected in the presence of small corruption (noise level is only 1). In real problems, objects of interest are, deliberately or not, buried under extremely rough surfaces in order to fool classifiers. In this section, we conduct an experiment to see how each method performs when the level of corruption increases in the separate-target scenario.Classification results of five different methods on different polarization combinations and different noise levels are shown in Figure 4.6. First of all, similar trends to small corruption can be observed in that SRC-SM shows best performance in all cases with bigger gaps occurring at high levels of noise. In addition, of the four SRC-related methods, SRC-CC is beaten by all three others when more than one polarization involved. This can be explained by the fact that SRC-CC suffers from the curse of dimensionality when each sample is represented by concatenating long vectors. It can also be seen that SRC-GT performs better than SRC-CR and SRC-CC in the presence of multiple polarizations. Last but not least, the best classification results can be seen at HH+HV and ALL among the five different combinations considered.

Effect of tensor dictionary learning on overall accuracy
We report the classification results for the all-target scenario with different noise levels.We also include the results of experiments with discriminative tensor dictionary learning methods. The results of HH+HV and ALL are reported, since they yield the best results, as observed in previous sections.The results of nine different methods are depicted in Figure 4.7. These methods include SVM (the dotted line), the four SRC-related methods (dashed lines), and their corresponding tensor dictionary learning counterparts (prefixed by TensorDL, solid  lines). We can see that except for the CC case, tensor dictionary learning methods outperform their corresponding SRC with gaps widening as the noise level increases. This observation confirms that tensor discriminative dictionary learning methods indeed provide accuracy improvements. Methods with the SM constraint once again emerge the winner in all noise levels, and the best accuracy numbers are observed using the HH+HV combination.

Multiple-relative-look classification accuracy
We describe a key real-world scenario where multi-look signals of an object of interest can be obtained. Figure 4.8a depicts the relative location of a radar carrier, a jet plane in this case, and an object of interest. The plane moves around the object at an angle corresponding to the blue arrow. One sample of object can be captured at this whole range, which can be seen as one of its looks. At the same time, the radar can also capture multiple looks of the object at smaller angles represented by green arrows. By continuing considering even smaller angles, more representatives of the object can be captured. These multiple views can provide complementary information of the object, highly likely resulting in better classification accuracy of the system.For the training samples, for each object, we generate two sets of signals. Each set contains samples captured after each 15 • , and each set has total of 24 views. Both sets start at the same relative angle but the first is captured by an integration angle of 30 • , the angle in the second set is 15 • . For the test samples, each object is represented by three signals: one by an integration angle of 30 • and two others by an integration angle of 15 • , as depicted in Figure 4.8a. Similar to previous experiments, test samples are captured at random relative angles. Ground samples are also simulated in the sameObject 30 • 15 • SRC 1 × 30 • b) 1look JSRC 2 × 15 • c) 2look ShiftSRC JSRC 1 × 30 • + 2 × 15 • d) 3lookShiftSRC a) way. Based on three signals captured, we establish three different way of using this information in the classification process:1. 1look : for each object, we use signals at integration angle of 30 • only. If only one polarization is used, an object of interest can be identified by SRC (and implicitly, SVM). If more than one polarization is involved, one object will be determined by SRC-SM, as this is the best method based on previous experiments (see Figure 4.8b).2. 2look : each object is represented by two singles captured at 15 • . This multi-look classification problem can be solved by joint SRC (JSRC)  #b23 , or the proposed relative-look SRC (ShiftSRC) (see Figure 4.8c).3. 3look : uses all three signals to represent an object. In this case, the relationship between the 30 • signal and the first 15 • signal can be modeled by the SRC-SM, while the relationship between two 15 • signals can be formed by either JSRC or ShiftSRC (see Figure 4.8d).For this experiment, we consider the all-target scenario and two polarization combinations, HH and HH+HV. It is worth noting that for the HH+HV case, there will be four channels in 2look and six channels in 3look. The results of different methods are shown in Figure 4.9. We can see that SVM still performs well at the lowest noise level (1), but drastically degrades with a little more corruption. On the other hand, SRC-based methods obtain good results even if the noise level is large for   the HH+HV combination. Of sparse representation methods, ShiftSRC outperforms the others with the gap becoming larger for highly corrupted signals. Interestingly, ShiftSRC at 2look provides even better results than JSRC does at 3look. These results confirm the advantages of the proposed relative-look sparse representation model.  

Overall accuracy on measured UWB SAR data
In this section, the results of this technique are illustrated using the data from the ARL UWB low-frequency SAR, which transmits radar signals occupying the frequency spectrum that span approximately from 50 to 1150 MHz  #b109 . Figure 4.10 shows a SAR image formed using data collected at Yuma Proving Grounds (YPG)  #b86 . The scene includes several rows of buried mines surrounded by clutter objects such as bushes, rocks, tire tracks, etc.The set contains signals of 50 targets and 50 confusers. Each signal has resolution of 90 × 30 and already includes noise from the ground. Visualization of six samples in each class are shown in Figure 4.11. We conduct the all-target experiment and report results of different methods on different polarization combinations in Figure 4.12. For each combination, three competing methods are considered: SVM, SRC, and TensorDL (both with the SM constraint). Since grounds are fixed in this data set, we report the results based on size of the training set. For each training size N (N =10, 20, 30, or 40), we randomly choose N samples from each class for training; the rest 50 − N samples are considered test samples.The results are reported in Figure 4.12 as the average of 10 tests. In general, the tensor dictionary learning performs better than sparse representation in all combinations except for the HH case. SVM also provides good results but is outperformed by other competing methods.  

Conclusion
We have developed a novel discrimination and classification framework for low-frequency UWB SAR imagery using sparse representation-based methods. The framework is applicable for either single channel or multiple channel (polarizations, multilook) SAR imagery. The techniques are tested and the discrimination/classification performance of targets of interest versus natural and manmade clutter in challenging scenarios is measured using both rigorous electromagnetic simulation data and real data from the ARL UWB radar. The classification results show encouraging potential of tensor sparsity methods, even when the test images are very noisy (buried under extremely rough ground surfaces), targets have small RCSs, and the targets' responses have very little detailed structures, i.e., targets are small compared to the wavelengths of the radar signals. The SRC-SM technique and its dictionary learning version consistently offers the best results with the combination of co-and cross-pol data, e.g., HH+HV or ALL. In addition, the non-negativity constraints on sparse tensor codes enhance the performance of the systems. Furthermore, we also show the ShiftSRC model is particularly suitable for problems with multiple-relative-look signals.

Chapter 5
Conclusions and Future Directions

Summary of Main Contributions
The overarching theme in this dissertation is the design of signal and image classification algorithms by exploiting structurally meaningful prior information of signal representations in associated models. Different discriminative models have been explored based on signal sparsity structures. We have primarily considered low-training classification scenarios where the different signal representations exhibit discriminative structure that can be leveraged for robustness benefits.In Chapter 2, we focus on extracting discriminative features of histopathological images that can be useful for classification and detection tasks. In particular, we based our contributions on dictionary learning to discriminative learning of complicated medical image features. By simply build one dictionary for each image class that promote small intra-class representation and prevent inter-class representation, we obtain class-specific dictionaries that explicitly capture crucial features. The framework is theoretically and experimentally shown to have a low complexity compared to other related methods. In order to verify that the framework is indeed applicable in a variety of scenarios, we conduct several experiments on three diverse histopathological datasets. It is illustrated our method is competitive with or outperforms state of the art alternatives, particularly in the regime of realistic or limited training set size. It is also shown that with minimal parameter tuning and algorithmic changes, the proposed method can be easily applied on different problems with different natures which makes it a good candidate for automated medical diagnosis instead of using customized and problem specific frameworks for every single diagnosis task. We also create a software toolbox available to help deploy the method widely as a diagnostic tool in existing histopathological image analysis systems. Particular problems such as grading and detecting specific regions in histopathology may be investigated using our proposed techniques. ! - ! !! shared features - - - ! ! low-rank constraint - - - - ! structured coefficients - - ! ! ! structured dictionaries - ! ! ! ! classification performance - - ! ! !!Chapter 3, we propose a generalized dictionary learning method for different image classification problem. Our primary contribution in this chapter is the development of a discriminative dictionary learning framework via the introduction of a shared dictionary with two crucial constraints. First, the shared dictionary is constrained to be low-rank. Second, the sparse coefficients corresponding to the shared dictionary obey a similarity constraint. In conjunction with a widely used discriminative model, this leads to a more flexible model where shared features are excluded before doing classification. An important benefit of this model is the robustness of the framework to size and the regularization parameter of the shared dictionary. In comparison with state-of-theart algorithms developed specifically for these tasks, the proposed model offers better classification performance on average. Another important contribution of this chapter is the dictionary learning toolbox -DICTOL. The toolbox implements many widely used generative and discriminative dictionary learning methods. Many classical methods are sped up via new numerical optimization innovations. Table 5.1 summarizes different characteristics of widely used dictionary learning methods and SRC. The proposed LRSDL requires a smallest amount of training time compared with other frameworks using their original algorithms. In terms of classification performance, two methods focusing on extracting shared features, COPAR [3] and LRSDL, outperform other methods with slightly better but much faster results provided by LRSDL, thanks to the efficient algorithm and low-rank structure.As an extension of discriminative sparsity models, we continue to propose different tensor sparsity structures for the problem of discriminating UWB-SAR imagery in Chapter 5. In this chapter, we present three novel sparsity-driven techniques, which not only exploit the subtle features of raw captured data but also take advantage of the polarization diversity and the aspect angle dependence information from multi-channel SAR data.First, the traditional sparse representation-based classification is generalized to exploit shared information of classes and various sparsity structures of tensor coefficients for multichannel data. Corresponding tensor dictionary learning models are consequently proposed to enhance classification accuracy. Lastly, a new tensor sparsity model is proposed to model responses from multiple consecutive looks of objects, which is a unique characteristic of the dataset we consider. Extensive experimental results on a high-fidelity electromagnetic simulated dataset and radar data collected from the U.S. Army Research Laboratory side-looking SAR demonstrate the advantages of proposed tensor sparsity models.

Potential Future Research Directions
The contributions in the previous chapters naturally point towards various directions for future research. We mention some of the possible extensions in this section.

Hierarchically shared feature learning
As proposed, the LRSDL model learns a dictionary shared by every class. In some practical problems, a feature may belong to more than one but not all classes. In future work, we will investigate the design of hierarchical models for extracting common features among classes.

Exploiting shared features using deep learning models
Deep learning has become a powerful framework for many image processing and computer vision applications such as image classification and object detection. To the best of our knowledge, there is no deep learning model that can reduce the effect of the shared features. As viable future research direction for this line of work, we propose to identify meaningful physical prior information for use in deep networks for extracting shared features and to demonstrate its benefits, especially in low training data scenarios.

Evolution of structured sparsity
Almost all dictionary learning methods enforce sparsity using 1 norm or 0 pseudo norm. It has been shown that Bayesian inference can effectively capture sparsity of signals by introducing new priors  #b110  #b111 . Amongst those priors, a well-suited sparsity promoting prior is Spike and Slab prior which is widely used in Bayesian inference  #b112  #b113  #b114 . In fact, it is acknowledged that Spike and Slab prior is indeed the gold standard for inducing sparsity in Bayesian inference  #b114 . Naturally, we can incorporate this prior into a dictionary learning framework to further boost the classification performance. The main obstacle of using this prior is that coefficient update optimization problem is known to be a hard non-convex problem where most of existing solutions involve simplifying assumptions and/or relaxation. Fortunately, this hard problem has been addressed by two very recent works, ICR  #b15  and AMP  #b31 . Both ICR and AMP propose algorithms to directly solve the problem while AMP can solve the problem very effectively. These promising results can be extended into a Bayesian dictionary learning framework to further enhance the performance.In this section, we compare the computational complexity for the proposed DFDL and competing dictionary learning methods: LC-KSVD  #b36 , FDDL  #b37 , and Nayak's  #b47 . The complexity for each dictionary learning method is estimated as the (approximate) number of operations required by each method in learning the dictionary. For simplicity, we assume that number of training samples, number of dictionary bases in each class are the same, which means: N i = N j = N, k i = k j = k, ∀i, j = 1, 2, . . . , c, and also L i = L j = L, ∀i, j = 1, 2, . . . , c. For the consitence, we have changed notations in those methods by denoting Y as training samples and X as the sparse code.In most of dictionary learning methods, the complexity of sparse coding step, which is often a l 0 or l 1 minimization problem, dominates that of dictionary update step, which is typically solved by either block coordinate descent  #b35  or singular value decomposition  #b16 . Then, in order to compare the complexity of different dictionary learning methods, we focus on comparing the complexity of sparse coding steps in each iteration.

A.1 Complexity of the DFDL
The most expensive computation in DFDL is solving an Orthogonal Matching Pursuit (OMP  #b65 ) problem. Given a set of samples Y ∈ R d×N , a dictionary D ∈ R d×k and sparsity level L, the OMP problem is:X * = arg min X 0 ≤L Y − DX 2 F .R. Rubinstein et al.  #b115  reported the complexity of Batch-OMP when the dictionary is stored in memory in its entirety as: T b-omp = N (2dk + L 2 k + 3Lk + L 3 ) + dk 2 . Assuming an asymptotic behavior of L k ≈ d N , the above expression can be simplified to:T b-omp ≈ N (2dk + L 2 k) = kN (2d + L 2 ). (A.1)This result will also be utilized in analyzing complexity of LC-KSVD.The sparse coding step in our DFDL consists of solving c sparse coding problems:X = arg min X 0 ≤L Ŷ − D iXi 2 F. WithŶ ∈ R d×cN , D i ∈ R d×k , each problem has complexity of k(cN )(2d + L 2 ). Then the total complexity of these c problems is: T DFDL ≈ c 2 kN (2d + L 2 ).

A.2 Complexity of LC-KSVD
We consider LC-KSVD1 only (LC-KSVD2 has a higher complexity) whose optimization problem is written as  #b36 :(D, A, X) = arg minD,A,X Y − DX 2 F + α Q − AX 2 F s.t. x i 0 ≤ L.and it is rewritten in the K-SVD form:(D, A, X) = arg minD,A,X Y √ αQ − D √ αA X 2 F s.t. x i 0 ≤ L. (A.2)Since Q ∈ R ck×cN and A ∈ R ck×ck ,Ỹ = Y √ αQ ∈ R (d+ck)×cN andD = D √ αA ∈ R (d+ck)×ck . Omitting the computation of scalar multiplications, the complexity of (A.2) is: T LC-KSVD ≈ (ck)(cN )(2(d + ck) + L 2 ) = c 2 kN (2d + 2ck + L 2 ).

A.3 Complexity of Nayak's
The optimization problem in Nayak's  #b47  is:(D, X, W) = arg minD,X,W Y − DX 2 F + λ X 1 + X − WY 2 F .X is estimated via the gradient descent method that is an iterative method whose main computational task in each iteration is to calculate the gradient of Q(X) = Y − DX 2 F + X − WY 2 F with respect to X. We have:∂Q(X) ∂X = 2 (D T D + I)X − (D T − W)Y .where D T D + I, and (D T − W)Y could be precomputed and at each step, only (D T D + I)X need to be recalculated after X is updated. With D ∈ R d×ck , X ∈ R ck×cN , Y ∈ R d×cN , W ∈ R ck×d , the complexity of the sparse coding step can be estimated as: with q being the average number of iterations needed for convergence. Here we have ignored matrix subtractions, additions and scalar multiplications and focused on matrix multiplications only. We have also used the approximation that complexity of AB is 2mnp where A ∈ R m×n , B ∈ R n×p . The first term in (A.3) is of D T D + I (note that this matrix is symmetric, then it needs only half of regular operations), the second term is of (D T −W)Y and the last one comes from q times complexity of calculating (D T D+I)X.

A.4 Complexity of FDDL
The sparse coding step in FDDL  #b37  requires solving c class-specific problems: . , X c ] respectively. The algorithm for solving this problem uses Iterative Projective Method  #b116  whose complexity depends on computing gradient of six Frobineous-involved terms in the above optimization problem at each iteration.X i = arg min X i Y i − DX i 2 F + Y i − D i X i i 2 F + c j=1,j =i D j X j i 2 F +λ 2 X i − M i 2 F − c k=1 M k − M 2 F + η X i 2 F + λ 1 X i 1 ,For the first three terms, the gradient could be computed as:2(D T D)X i − 2D T Y i +         2(D T 1 D 1 )X 1 i . . . 2(D T i D i )X i i − D T i Y i . . . 2(D T c D c )X c i         , (A.5)where D T D, and D T Y i could be precomputed with the total cost of (ck)d(ck) + 2(ck)dN = cdk(2N + ck); D T i D i , and D T i Y i could be extracted from D T D, and D T Y i at no cost; at each iteration, cost of computing (D T D)X i is 2(ck) 2 N , each of (D T j D j )X j i could be attained in the intermediate step of computing (D T D)X i . Therefore, with q iterations, the computational cost of (A.5) is:cdk(2N + ck) + 2qc 2 k 2 N. (A.6)For the last three terms, we will prove that:∂ ∂X i X i − M i 2 F = 2(X i − M i ), (A.7) ∂ ∂X i c k=1 M k − M 2 F = 2(M i − M), (A.8) ∂ ∂X i η X i 2 F = 2ηX i . (A.9)Indeed, let E m,n be a all-one matrix in R m×n , one could easily verify that: Thus, (A.7) can be obtained by:M k = 1 N X k E N,N ; M = 1 cN XE cN,N = 1 cN c i=1 X i E N∂ ∂X i X i − M i 2 F = ∂ ∂X i X i − 1 N X i E N,N 2 F = ∂ ∂X i X i (I − 1 N E N,N ) 2 F = 2X i (I − 1 N E N,N )(I − 1 N E N,N ) T = 2X i (I − 1 N E N,N ) = 2(X i − M i ).For (A.8), with simple algebra, we can prove that:∂ ∂X i M i − M 2 F = 2(c − 1) cN (M i − M)E N,N = 2(c − 1) c (M i − M). ∂ ∂X i M k − M 2 F = 2 cN (M − M k )E N,N = 2 c (M − M k ), (k = i).Compared to (A.5), calculating (A.7), (A.8) and (A.9) require much less computation. As a result, the total cost of solving X i approximately equals to (A.6); and the total estimated cost of sparse coding step of FDDL is estimated as c times cost of each classspecific problem and approximately equals to:T FDDL ≈ c 2 dk(2N + ck) + 2qc 3 k 2 N = c 2 kN (2d + 2qck) + c 3 dk 2 .Final analyzed results of these four methods are reported in Table 2.1.

Appendix B
Proof of Lemmas in Chapter 3

B.1 Proof of Lemma 1
Let w c ∈ {0, 1} K is a binary vector whose j-th element is one if and only if the j-th columns of D belong to D c , and W c = diag(w c ). We observe that D c X c i = DW c X i . We can rewrite f Y,X (D) as:Y − DX 2 F + C c=1 Y c − D c X c c 2 F + j =c D j X j c 2 F = Y − DX 2 F + C c=1 Y c − DW c X c 2 F + j =c DW j X c 2 F = trace   XX T + C c=1 C j=1 W j X c X T c W T j D T D   , −2trace YX T + C c=1 Y c X T c W c D T + constant, = −2trace(ED T ) + trace(FD T D) + constant.where we have defined: E = YX T + C c=1 Y c X T c W c = YX T + Y 1 (X 1 1 ) T . . . Y C (X C C ) T , = Y     X T +     (X 1 1 ) T . . .F = XX T + C c=1 C j=1 W j X c X T c W T j = XX T + C j=1 W j C c=1 X c X T c W T j , = XX T + C j=1 W j XX T W T j .Let: From definition of W j , we observe that 'left-multiplying' a matrix by W j forces that matrix to be zero everywhere except the j-th block row. Similarly, 'right-multiplying' a matrix by W T j = W j will keep its j-th block column only. Combining these two observations, we can obtain the result: Lemma 1 has been proved.XX T = A =       A 11 . . . AW j AW T j =       0 . . .

B.2 Proof of Lemma 2
We need to prove two parts:For the gradient of f , first we rewrite: Now, by letting V =Ỹ +Ŷ 2 , Lemma 3 has been proved.f (Y, D, X) = C c=1 r(Y c , D, X c ) =       Y 1 Y 2 . . . Y C Y 1 0 . . .

Footnote
1 : The preliminary version of this work was presented in IEEE Radar Conference, 2017[104] 
4 : https://github.com/tiepvupsu/tensorsparsity
2 : Note that a higher ground scale means more noisy images. Henceforth, in the text as well as figures we simply refer to ground scale as noise level for ease of exposition.
3 : Based on this observation, from now on, all other results are implicitly reported with the nonnegativity constraint.